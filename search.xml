<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>有寫就好｜面對焦慮</title>
    <url>/%E6%9C%89%E5%AF%AB%E5%B0%B1%E5%A5%BD%EF%BD%9C%E9%9D%A2%E5%B0%8D%E7%84%A6%E6%85%AE/</url>
    <content><![CDATA[<p>感覺周圍最近抱怨「大環境」的言論甚囂塵上，自己也難免受此影響，有些焦慮。焦慮的時候讀書總不會錯的，這裡紀錄一些最近看到的段落：</p>
<p><strong>《宇宙》裡卡爾薩根在回顧人類發展史的時候說：</strong></p>
<blockquote>
<p>「讓我們回望過去。數不清的年月前，潮起潮落的灘塗裡，生命逐漸成形。他掙扎著變成一個又一個不同的形狀，攫取了一種又一種不同的力量，終於自信地爬上陸地。經過一代又一代的變化，他控制了天空，也潛入了黑暗的深淵；我們看著他在憤怒和飢餓中重塑自身,看著他越來越像我們。他不斷伸展，不斷優化，向著難以置信的目標一刻不停地前進。然後，他變成了我們，生命的韻律至今在我們的大腦和動脈中搏動……」</p>
</blockquote>
<p><strong>美國最高法院首席大法官約翰·羅伯茨(John Roberts)，參加兒子的初中畢業典禮時的演講：</strong></p>
<p>From time to time in the years to come, I hope you will be treated unfairly, so that you will come to know the value of justice.<br>我希望在未來歲月中，你能時不時地遭遇不公，唯有如此，你才能懂得公正的價值。</p>
<p>I hope that you will suffer betrayal because that will teach you the importance of loyalty.<br>我希望你嚐到背叛的滋味，這樣你才能領悟到忠誠之重要。</p>
<p>Sorry to say, butI hope you will be lonely from time to time so that you don’t take friends for granted.<br>抱歉，我還希望你們時常感到孤獨，唯有如此，你才 不會視朋友為理所當然。</p>
<p>I wish you bad luck,again, from time to time so that you will be conscious of the role of chance in life and understand that your success is not completely deserved and that the failure of others is not completely deserved either.<br>我祝你們偶爾運氣不佳，這樣你才會意識到機遇在人 生中扮演的⻆色，從而明白你的成功並非天經地義， 而他人的失敗也不是命中註定。</p>
<p>And when you lose, as you will from time to time, I hope every now and then, your opponent will gloat over your failure. It is a way for you to understand the importance of sportsmanship.<br>當你偶爾失敗時，我願你的對手時不時地會幸災樂 禍。這樣你才能懂得互相尊重的競技精神的重要。</p>
<p>I hope you’ll be ignoredso you know the importance of listening to others.<br>我希望你被人無視，唯有如此，你才懂得傾聽他人有多重要。</p>
<p>And I hope you will have just enough painto learn compassion.<br>我祝你感受足夠的痛楚來學會同情。</p>
<p>Unless you are perfect, it does not mean don’t make any changes.<br>除非你完美無瑕，那麼這句話絕不意味著不去改變自己。</p>
<p>“The unexamined life is not worth living.”<br>未經自省的人生沒有意義。</p>
<p>20 mins</p>
]]></content>
      <categories>
        <category>Daily</category>
      </categories>
      <tags>
        <tag>reading notes</tag>
      </tags>
  </entry>
  <entry>
    <title>有寫就好｜說清楚，講明白</title>
    <url>/%E6%9C%89%E5%AF%AB%E5%B0%B1%E5%A5%BD%EF%BD%9C%E8%AA%AA%E6%B8%85%E6%A5%9A%EF%BC%8C%E8%AC%9B%E6%98%8E%E7%99%BD/</url>
    <content><![CDATA[<p>最近發生了幾件小事，正好應和題目，就此記錄一下。</p>
<p>「把話說清楚」是表達最基本的要求，但想做好，其實並不簡單。上週「系統分析與設計」課堂報告，要求不多，就是前三週的上課內容。但大多數組別的報告，都沒有讓老師滿意，問題出在「這節課不需要你們把系統設計的很複雜，重點是要說清楚、講明白」。</p>
<p>什麼叫「說清楚、講明白」？用這節課來舉例就是：從「需求分析」到「需求塑模」，每一步驟都需要按部就班，先說清楚每個步驟需要怎樣的方法和規則，需要用到哪些工具來呈現（活動圖、使用個案圖等），我們又是怎麼依照這些規則，用這些工具來完成我們的設計。要邏輯清楚，重點明確。</p>
<p>另一件事發生在導師的課堂作業，9組有8組被退回重寫，讀了這麼多年書，這種情況也是頭一回。作為助教，把作業發給老師之前，我其實都會大概看一下每組的內容，這次的要求是分析一家公司的數位策略，粗略看過之後覺得都還不錯呀，實在想不明白為什麼都要退回重寫。</p>
<p>解鈴還須繫鈴人「大家太愛寫模稜兩可的答案，回答全是『都可以』。但是分析和做決策的時候，一定要找到一兩個關鍵人事物，也就是80/20法則中最重要的那20%。要杜絕『囫圇吞棗』式的做事、做決策的方式，事實上不存在『都可以』這個選項，任何選擇都是有代價的，但做決策的時候要習慣想清楚、選一邊，然後堅決的『踩下去』。即使選錯邊也沒有關係，可以再反省、檢討。但是如果一開始就都選，或者都不選的話，你做對了什麼，做錯了什麼，是完全弄不清楚的。」我也算是又上了一課，也反思自己在「想清楚、講清楚、寫清楚」這些幾個方面都有太多需要精進的，而且時常會受到惰性的蠱惑，陷入「差不多得了」的想法，以後要杜絕。</p>
<p>最後，分享輕鬆一點的，王興以前的blog中寫道「據說，把想法寫下來有助於思考，因為只有想清楚的事情才能寫得出來。所以，我正努力多寫。」看來大佬有時也困於「想清楚，寫明白」，多少安慰到了我。</p>
]]></content>
      <categories>
        <category>Daily</category>
      </categories>
      <tags>
        <tag>reflection</tag>
      </tags>
  </entry>
  <entry>
    <title>有寫就好｜說人話</title>
    <url>/%E6%9C%89%E5%AF%AB%E5%B0%B1%E5%A5%BD%EF%BD%9C%E8%AA%AA%E4%BA%BA%E8%A9%B1/</url>
    <content><![CDATA[<p>前段時間寫文章，總覺得不得要領。</p>
<p>論述的文章還算好寫，想清楚論點，說明白論據，有一定邏輯，基本都是能看的。但是，稍微有點描述性，需要表達情感的文章就麻煩了，寫的狗屁不通是常有的事情。以前看到一篇邏輯清晰，語言簡潔的文章不覺得怎樣。現在來看，只能感慨其功底的深厚。</p>
<p>不過，寫的漸漸多了之後，雖然精進不多，但也算有了一點心得體會。</p>
<p>首先，感動筆。當你有寫文章需求的時候，甭管以前寫的有多爛，有多怕寫文章，都要感快動筆寫起來。就像系統開發裏常說的 prototype，你先寫出個雛型，再慢慢修改。不管是你自己讀，還是拿給別人修改，都是一種反饋，有了反饋再去做修正。修正的多了，就算是垃圾堆，最後也能修出個像模像樣的東西來。怕的就是開始顧慮太多，然後一拖再推，最後信心被拖垮了，就更寫不出來了。</p>
<p>其次，說人話。這一點真的很難做到，我經常就是寫著寫著，句子不自覺就拗口起來，一句話恨不得，要轉折個五六次，才說到重點。避免這個問題，有個簡單的辦法 —— 善用逗號。這是我在讀導師寫的文章時，發現的一個小訣竅。她寫文章很少出現文縐縐的長句，每句話都不長，旨在把內容表達清楚，而不追求引經據典、炫耀文筆。所以讀起來清新流暢，十分舒服。後來，我也模仿這個方式，盡量每句話說的精簡到位，避免用冗長、重複的句子表達。多練幾次，真的會通順不少。</p>
<p>不過，想要把文章寫好，寫的流暢，讓人讀起來舒服，還是唯手熟爾。所以多寫啊！</p>
]]></content>
      <categories>
        <category>Daily</category>
      </categories>
      <tags>
        <tag>reflection</tag>
      </tags>
  </entry>
  <entry>
    <title>有寫就好｜重新開始寫作</title>
    <url>/%E6%9C%89%E5%AF%AB%E5%B0%B1%E5%A5%BD%EF%BD%9C%E9%87%8D%E6%96%B0%E9%96%8B%E5%A7%8B%E5%AF%AB%E4%BD%9C/</url>
    <content><![CDATA[<p>忙忙碌碌的2022上半年就這麼倏忽而過，最近決定重新開始寫一寫文章。</p>
<p>其一，因為近期在寫論文的過程中，明顯感覺自己組織長篇文章的能力實在太差。<br>其二，也想要好好審視一下自己、紀錄一下生活。同時也是希望可以慢慢培養出寫作的習慣。</p>
<p>最近在聽池大的 podcast<a href="https://app.podcastguru.io/podcast/mactalk-1619054900" target="_blank" rel="noopener">「MacTalk·夜航西飞」</a>，裡面有一期和孟岩的聊天，講到二人堅持寫作這件事情，很多人會質疑「你創業工作這麼忙了，怎麼會還有自己的時間寫東西」。大家一方面，驚訝於二人的時間管理，另一方面不理解堅持寫作的意義。</p>
<p>孟岩就提到芒格曾說的一個故事：</p>
<blockquote>
<p>當我在給一隻黑猩猩講解一件事情的時候，最終會留下什麼呢？</p>
<p>一頭霧水的黑猩猩，和一個更理解這件事情的我自己。</p>
</blockquote>
<p>寫作的意義是梳理，是reset的過程。有些事情我們以為自己了解了，但當需要給別人講解的時候，又變得十分困難。時常沒辦法非常迅速的組織出一套清晰且有邏輯的說詞。本質上還是我們對於這件事的理解不夠深入，把「知道了」誤以為「理解了」。</p>
<p>寫作的好處就在於，可以幫助你再一次的梳理。寫的過程就是重新思考，重新構建的過程。就像第一遍，你憑感覺搭了一個樂高城堡，但發現怪怪的。第二遍，就看著說明書，把各個部分又重新搭建了一遍。寫作的過程就像是第二遍看說明，只不過這個說明書要你自己總結。</p>
]]></content>
      <categories>
        <category>Daily</category>
      </categories>
      <tags>
        <tag>reflection</tag>
      </tags>
  </entry>
  <entry>
    <title>分類演算法實作 Titanic disaster dataset</title>
    <url>/Titanicdataset/</url>
    <content><![CDATA[<h2 id="資料處理流程"><a href="#資料處理流程" class="headerlink" title="資料處理流程"></a>資料處理流程</h2><ol>
<li>資料前處理<ul>
<li>簡單的Feature Engineering<ul>
<li>只保留Cabin的艙位號（前面的字母）。</li>
<li>把Name中的有一定含義的 title 元素提取出來，並將比較少用的title合併到比較常用的tittle中，建立一個新的類別“Title”</li>
<li>把姓氏提取出來，創建新的類別“Surname”</li>
</ul>
</li>
<li>Missing Data<ul>
<li>NA值 &amp; 空白值</li>
</ul>
</li>
<li>減少資料量<ul>
<li>屬性的篩選：刪掉不要的屬性</li>
</ul>
</li>
<li>正規化處理</li>
</ul>
</li>
<li>模型的建立<ul>
<li>隨機森林（Random Forest）</li>
<li>SVM（Support Vector Machines）</li>
<li>GBM（Gradient Boosting Machine）</li>
</ul>
</li>
<li>模型的解釋</li>
<li>預測及分析<ul>
<li>混淆矩陣</li>
<li>ROC</li>
<li>AUC</li>
</ul>
</li>
</ol>
<h2 id="資料前處理"><a href="#資料前處理" class="headerlink" title="資料前處理"></a>資料前處理</h2><h3 id="簡單的Feature-Engineering："><a href="#簡單的Feature-Engineering：" class="headerlink" title="簡單的Feature Engineering："></a>簡單的Feature Engineering：</h3><ul>
<li>只保留Cabin的艙位號（前面的字母）。</li>
<li>把Name中的有一定含義的 title 元素提取出來，並將比較少用的title合併到比較常用的tittle中，建立一個新的類別“Title”</li>
<li>把姓氏提取出來，創建新的類別“Surname”<br><img src="https://img-blog.csdnimg.cn/20210630161713992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><h3 id="Missing-data："><a href="#Missing-data：" class="headerlink" title="Missing data："></a>Missing data：</h3></li>
</ul>
<p>NA值主要來自Age和Cabin（Survived的缺失值，是test中填補的NA）</p>
<p><img src="https://img-blog.csdnimg.cn/20210630162043986.png#pic_center" alt="在这里插入图片描述"></p>
<pre><code>方法：這邊我們選擇用mice填補Age和Fare的缺失值

查看填補之後的結果：</code></pre><p><img src="https://img-blog.csdnimg.cn/20210630162117560.png" alt="在这里插入图片描述"></p>
<p>空值：只來自Embarked</p>
<p>  <img src="https://img-blog.csdnimg.cn/20210630162218181.png" alt="在这里插入图片描述"></p>
<pre><code>查看Embarked的類別及各個類別的資料筆數，選擇資料筆數最的類別（“S”）填補填補到Embarked的空值中</code></pre><p><img src="https://img-blog.csdnimg.cn/20210630162440826.png" alt="在这里插入图片描述"></p>
<h3 id="減少資料量："><a href="#減少資料量：" class="headerlink" title="減少資料量："></a>減少資料量：</h3><p>屬性的篩選：刪掉不要的屬性</p>
<ul>
<li>Name &amp; Surname：類別太多了，並且沒有什麼特別的用途。</li>
<li>Ticket：裡面都是一些隨機的數字，沒有特多含義，並且是多值屬性不好處理。</li>
<li>Cabin：有太多的NA值，並且為類別變數不好填充，如果給一個Ncabin的類別，會使得屬性非常unbalance。</li>
<li>PassengerId：只是一個序列號，沒有太多的含義。<img src="https://img-blog.csdnimg.cn/2021063016251447.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><h3 id="Data-正規化："><a href="#Data-正規化：" class="headerlink" title="Data 正規化："></a>Data 正規化：</h3></li>
</ul>
<p>數值變量的range沒有特別的大，所以沒有做特別的正規化處理</p>
<h2 id="模型的建立"><a href="#模型的建立" class="headerlink" title="模型的建立"></a>模型的建立</h2><p>因為test 資料集中沒有“Survuved”欄位，所以我們從train資料集中分出30%作為驗證集。</p>
<p>剩下的train中的70%資料用於訓練模型，訓練中也會做cross-validation。</p>
<p>下面建立了三個模型：</p>
<ul>
<li>隨機森林（Random Forest）</li>
<li>SVM（Support Vector Machines）</li>
<li>GBM（Gradient Boosting Machine）</li>
<li>⚠️ KNN一般可以作為分類的baseline</li>
</ul>
<h3 id="隨機森林："><a href="#隨機森林：" class="headerlink" title="隨機森林："></a>隨機森林：</h3><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 隨機森林</span></span><br><span class="line">set.seed(<span class="number">100</span>)</span><br><span class="line">titanic_rf &lt;- train(factor(Survived) ~ ., data=train_data, method=<span class="string">'rf'</span>, </span><br><span class="line">										trControl=trainControl(method=<span class="string">"cv"</span>, number=<span class="number">5</span>))</span><br><span class="line">titanic_rf</span><br><span class="line">plot(titanic_rf)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20210630162556173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我們可以看出選擇出的最好的模型是mtry = 3的時候。</p>
<h3 id="SVM："><a href="#SVM：" class="headerlink" title="SVM："></a>SVM：</h3><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># SVM</span></span><br><span class="line">set.seed(<span class="number">100</span>)</span><br><span class="line">titanic_svm &lt;- train(factor(Survived) ~., data=SVMtrain_data, method=<span class="string">'svmRadial'</span>, preProcess= c(<span class="string">'center'</span>, <span class="string">'scale'</span>), </span><br><span class="line">                     trControl= trainControl(method=<span class="string">"cv"</span>, number=<span class="number">5</span>, classProbs = <span class="literal">T</span>))</span><br><span class="line">titanic_svm</span><br><span class="line">plot(titanic_svm</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20210630162643796.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我們可以看出最好的模型是 sigma=0.2828，C=0.25的時候。</p>
<h3 id="GBM："><a href="#GBM：" class="headerlink" title="GBM："></a>GBM：</h3><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># (GBM) model</span></span><br><span class="line">set.seed(<span class="number">100</span>)</span><br><span class="line">titanic_gbm &lt;- train(factor(Survived) ~., data=train_data, method=<span class="string">'gbm'</span>, preProcess= c(<span class="string">'center'</span>, <span class="string">'scale'</span>), </span><br><span class="line">                     trControl=trainControl(method=<span class="string">"cv"</span>, number=<span class="number">7</span>), verbose=<span class="literal">FALSE</span>)</span><br><span class="line">print(titanic_gbm)</span><br><span class="line">plot(titanic_gbm)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20210630162715791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我們可以看出GBM選出的最好的模型是n.trees=200，且深度為3 interaction.depth = 3的模型。</p>
<h2 id="模型的解釋"><a href="#模型的解釋" class="headerlink" title="模型的解釋"></a>模型的解釋</h2><p>這裡直接利用<code>library(&quot;DALEX&quot;)</code>包的解釋函數對三個模型進行解釋性分析</p>
<h3 id="累積殘差分佈："><a href="#累積殘差分佈：" class="headerlink" title="累積殘差分佈："></a>累積殘差分佈：</h3><p><img src="https://img-blog.csdnimg.cn/20210630162745616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>由上圖我們可以看，綠色的線在最上方，也就是SVM中大部分的樣本殘差都比較大。而紅色的線是RF模型，它的大部分的樣本殘差都比較小。可以看出樹的模型的殘差線對於SVM這類的模型都要來的比較小一些。</p>
<h3 id="變數重要性分析："><a href="#變數重要性分析：" class="headerlink" title="變數重要性分析："></a>變數重要性分析：</h3><p><img src="https://img-blog.csdnimg.cn/20210630162825232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>可以看出三個模型中的變數重要性的排序基本上是一樣的。</p>
<h2 id="測試訓練好的模型並分析結果"><a href="#測試訓練好的模型並分析結果" class="headerlink" title="測試訓練好的模型並分析結果"></a>測試訓練好的模型並分析結果</h2><p>我們用之前從train的資料集中分出的valid資料來做各個模型的測試</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用不同的已經訓練好的模型分類預測：</span></span><br><span class="line">rf_probs = predict(titanic_rf,valid_feature,type = <span class="string">"prob"</span>) <span class="comment"># 訓練集中的預測情形</span></span><br><span class="line">svm_probs = predict(titanic_svm,valid_feature,type = <span class="string">"prob"</span>)</span><br><span class="line">gbm_probs = predict(titanic_gbm,valid_feature,type = <span class="string">"prob"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="預測出來的結果（這邊僅以Random-Forrest的處理過程為例）："><a href="#預測出來的結果（這邊僅以Random-Forrest的處理過程為例）：" class="headerlink" title="預測出來的結果（這邊僅以Random Forrest的處理過程為例）："></a>預測出來的結果（這邊僅以Random Forrest的處理過程為例）：</h3><p>如圖：<br><img src="https://img-blog.csdnimg.cn/20210630162927787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看訓練集的預測情形</span></span><br><span class="line">rf_summaryvalid &lt;- rf_validDataPred %&gt;% </span><br><span class="line">  filter(yes &gt; <span class="number">0.5</span>) %&gt;%                           <span class="comment"># yes 為預測存活下來的機率</span></span><br><span class="line">  summarise(count = n(), </span><br><span class="line">            accuracy_rate = mean(Survived))              <span class="comment">#  統計預測存活下來的人數與實際比較的準確率</span></span><br><span class="line"></span><br><span class="line">rf_summaryvalid</span><br><span class="line"><span class="comment"># count  accuracy_rate</span></span><br><span class="line"><span class="comment"># 106	 0.6981132</span></span><br></pre></td></tr></table></figure>

<p>我們將是否存活的機率的門檻設置為0.5，我們可以看到計算出來的準確率為：0.6981132</p>
<p>我們想了解不同門檻值的預測情況，所以就先粗略切了[0,0.5,0.55,0.6,0.65,0.7,0.8,1]這些區間來看看，是否有更好的門檻值設定。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看測試集分類機率在不同門檻值下的預測情況</span></span><br><span class="line">rf_summaryvalidCut &lt;- rf_validDataPred %&gt;% </span><br><span class="line">  <span class="comment"># 看不同的分類機率做區間查看其準確率</span></span><br><span class="line">  mutate(interval = cut(yes,breaks = c(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">0.55</span>,<span class="number">0.6</span>,<span class="number">0.65</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">1</span>),include.lowest = <span class="literal">T</span>)) %&gt;%  </span><br><span class="line">  group_by(interval) %&gt;%</span><br><span class="line">  summarise(count = n(), </span><br><span class="line">            accuracy_rate = mean(Survived))</span><br><span class="line"></span><br><span class="line">rf_summaryvalidCut</span><br></pre></td></tr></table></figure>

<p>根據下表的分佈情況似乎切在0.8左右會更好<br><img src="https://img-blog.csdnimg.cn/20210630163015754.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="混淆矩陣-："><a href="#混淆矩陣-：" class="headerlink" title="混淆矩陣 ："></a><strong>混淆矩陣 ：</strong></h3><p>那麼我將預測結果依照分類機率大於0.8當成1來建立混淆矩陣，並對三個模型都建立了混淆矩陣來進行對比：<img src="https://img-blog.csdnimg.cn/20210630163057830.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>可以看出三個模型：</p>
<ul>
<li><p>預測的準確率（Accuracy）以及F1 Score 最高的都是 Random Forrest</p>
</li>
<li><p>三個模型主要犯的都是FN（false negative）的錯誤，既將實際存活的人判斷為了死亡。</p>
</li>
<li><p>同時我們可以看到SVM在準確率（Accuracy）上和其他兩個模型相差的並不多，但是 F1 Score 的分數就要比其他兩個模型低很多。</p>
<ul>
<li><p>Accuracy = (TP+TN)/(TP+FP+FN+TN)</p>
</li>
<li><p>Recall = TP/(TP+FN)</p>
</li>
<li><p>Precision = TP/(TP+FP)</p>
</li>
<li><p>F1-score = 2 * Precision * Recall / (Precision + Recall)</p>
<p>那麼我們可以根據F1-score 的公式看出他是Precision和Recall两者調和平均，而Precision和Recall两者可以比較好的度量分類錯誤的情況。所以我們可以推測出SVM的模型對於FP和FN的判斷不是很好，但對於TP和TN的預測效果還是可以的。</p>
</li>
</ul>
</li>
</ul>
<h3 id="ROC："><a href="#ROC：" class="headerlink" title="ROC："></a>ROC：</h3><p>上面的混淆矩陣我是透過比較粗糙的方式切出的 0.8 作為門檻來進行三個模型的比較的。</p>
<p>但是想進一步比較三個模型效果還是應該來看一個更為細緻的ROC曲線和AUC的值。</p>
<p>紅線為：Random Forest</p>
<ul>
<li>最佳的切分值：0.835 or 0.737</li>
</ul>
<p>綠線為：SVM</p>
<ul>
<li>最佳的切分值：0.808 or 0.798</li>
</ul>
<p>藍線為：GBM</p>
<ul>
<li>最佳的切分值：0.885 or 0.717</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20210630163241918.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在ROC的圖中越是靠近左上角的部分他的TPR越大而FPR越小，也就是模型的效果就越好。可以看出藍線和紅線都完全包裹在綠線的外面，所以我們可以認為Random Forest和GBM做為這個資料集的分類器效果都比SVM更好。而Random Forest和GBM的比較我們我們只從ROC不能看出哪一個模型比較好，所以我們需要進一步分析兩個模型的AUC值。</p>
<h3 id="AUC："><a href="#AUC：" class="headerlink" title="AUC："></a>AUC：</h3><p>AUC也就是ROC曲線下方的面積，AUC值越大的分類器，正確率越高。</p>
<p>根據 AUC 比較模型的效果也就是：Random Forest(0.844) &gt; GBM(0.836) &gt; SVM(0.795)</p>
]]></content>
  </entry>
  <entry>
    <title>文字探勘-2｜斷詞以及tidy形式的轉換</title>
    <url>/%E6%96%87%E5%AD%97%E6%8E%A2%E5%8B%98-2%EF%BD%9C%E6%96%B7%E8%A9%9E%E4%BB%A5%E5%8F%8Atidy%E5%BD%A2%E5%BC%8F%E7%9A%84%E8%BD%89%E6%8F%9B/</url>
    <content><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><h2 id="涉及的知識點"><a href="#涉及的知識點" class="headerlink" title="涉及的知識點"></a>涉及的知識點</h2><ul>
<li>tidy形式的轉換</li>
<li>斷句</li>
<li>斷詞</li>
</ul>
<h2 id="會用到的packages"><a href="#會用到的packages" class="headerlink" title="會用到的packages"></a>會用到的packages</h2><p>會用到的packages和函數：</p>
<ul>
<li><p><strong>library(dplyr)</strong>：整合所有在前處理數據會常用的“邏輯”，加入pipeline的概念</p>
<ul>
<li>select()：挑選特定column出來</li>
<li>filter()：自訂條件濾掉column中的資料</li>
<li>arrange()：調整row排列順序</li>
<li>mutate()：以現有的column資料做運算，形成新的column</li>
<li>summarise()：將目前的資料做統計運算，形成統計結論</li>
<li>tibble()：將典型的字符向量变成 tidy 文本数据集</li>
</ul>
</li>
<li><p><strong>library(jiebaR)</strong>：用於斷詞（ref：<a href="https://zhuanlan.zhihu.com/p/35846130" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35846130</a> ）</p>
<ul>
<li>worker()：初始化斷詞引擎<ul>
<li>stop_word=”stop_word.txt”：停用詞</li>
<li>user=”xxx.txt”：自定義詞庫：可以自己定義，也可以借用搜狗細胞詞庫，有大量專業領域詞彙</li>
<li>bylines = TRUE：不保留標點符號</li>
<li>注意：user=”xxx.txt” 以及 stop_word=”stop_word.txt”的txt檔案一定要是UTF-8編碼的格式</li>
</ul>
</li>
<li>segment()：斷詞（一般配合supply來寫成function使用）</li>
<li>filter_segment()：在前面worker()過濾後的基礎上，再次過濾</li>
</ul>
</li>
<li><p><strong>library(tidytext)</strong>：</p>
<ul>
<li>unnest_tokens()：將文本拆分成tokens，轉換成tidy的格式</li>
</ul>
</li>
<li><p><strong>library(tidyr)</strong>：重新定義資料框，留下繪圖需要的點</p>
<ul>
<li>spread()：</li>
<li>gather()：</li>
<li>separate(): 將 info 欄位以分號分割成三個欄位，並且直接放進原 data frame 中</li>
</ul>
</li>
</ul>
<h1 id="實作"><a href="#實作" class="headerlink" title="實作"></a>實作</h1><h2 id="讀取資料以及packages"><a href="#讀取資料以及packages" class="headerlink" title="讀取資料以及packages"></a>讀取資料以及packages</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 避免中文亂碼</span><br><span class="line">Sys.setlocale(category = &quot;LC_ALL&quot;, locale = &quot;zh_TW.UTF-8&quot;) </span><br><span class="line"></span><br><span class="line"># 載入資料</span><br><span class="line">library(dplyr)</span><br><span class="line">library(tidytext)</span><br><span class="line">library(wordcloud2)</span><br><span class="line">library(data.table)</span><br><span class="line">library(ggplot2)</span><br><span class="line">library(wordcloud)</span><br><span class="line">library(tidyr)</span><br><span class="line">library(jiebaR)</span><br><span class="line"></span><br><span class="line"># 把文章和留言讀進來</span><br><span class="line">MetaData = read.csv(&apos;./data/PTTcoin_articleMetaData.csv&apos;,encoding = &apos;UTF-8&apos;)</span><br><span class="line">Reviews  = read.csv(&apos;./data/PTTcoin_articleReviews.csv&apos;,encoding = &apos;UTF-8&apos;)</span><br><span class="line"></span><br><span class="line">MetaData$sentence &lt;- as.character(MetaData$sentence)</span><br><span class="line">Reviews$cmtContent &lt;- as.character(Reviews$cmtContent)</span><br><span class="line"></span><br><span class="line"># 挑選文章對應的留言</span><br><span class="line">Reviews = left_join(MetaData, Reviews[,c(&quot;artUrl&quot;, &quot;cmtContent&quot;)], by = &quot;artUrl&quot;)</span><br><span class="line"></span><br><span class="line"># 查看讀進來的資料</span><br><span class="line">str(Reviews)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/R/SMA/2-%E8%AE%80%E9%80%B2%E4%BE%86%E7%9A%84%E5%8E%9F%E5%A7%8B%E8%B3%87%E6%96%99.png?raw=true" alt="讀進來的原始資料"> </p>
<h2 id="斷詞"><a href="#斷詞" class="headerlink" title="斷詞"></a>斷詞</h2><h3 id="初始化斷詞引擎"><a href="#初始化斷詞引擎" class="headerlink" title="初始化斷詞引擎"></a>初始化斷詞引擎</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 初始化斷詞引擎</span><br><span class="line">jieba_tokenizer &lt;- worker(stop_word = &quot;./stop_words.txt&quot;,user=&quot;./user_dict.txt&quot;)</span><br></pre></td></tr></table></figure>

<p>我們將設置好的斷詞引擎加入我們寫好的斷詞函式中，方便在在我們資料格式中斷詞</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 自定義斷詞函式</span><br><span class="line">chinese_tokenizer &lt;- function(t) &#123;</span><br><span class="line">  lapply(t, function(x) &#123;</span><br><span class="line">    tokens &lt;- segment(x, jieba_tokenizer)</span><br><span class="line">    tokens &lt;- tokens[nchar(tokens)&gt;1]</span><br><span class="line">    return(tokens)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 將原始資料斷詞</span><br><span class="line">tokens &lt;- MetaData %&gt;% </span><br><span class="line">  unnest_tokens(word, sentence, token=chinese_tokenizer)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 格式化日期欄位</span><br><span class="line">tokens$artDate &lt;- tokens$artDate %&gt;% as.Date(&quot;%Y/%m/%d&quot;)</span><br><span class="line"></span><br><span class="line"># 過濾特殊字元</span><br><span class="line">tokens &lt;- tokens %&gt;% </span><br><span class="line">  filter(!(word %in% stop_words)) %&gt;% # 去掉停用字裡的一些詞彙</span><br><span class="line">  filter(!grepl(&apos;[[:punct:]]&apos;,word)) %&gt;% # 去標點符號</span><br><span class="line">  filter(!grepl(&quot;[&apos;^0-9a-z&apos;]&quot;,word)) %&gt;% # 去英文、數字</span><br><span class="line">  filter(nchar(.$word)&gt;1) </span><br><span class="line">  # select(-artDate, -artUrl)</span><br><span class="line"></span><br><span class="line">head(tokens, 20)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/R/SMA/2-%E5%89%8D20%E7%9A%84tokens.png?raw=true" alt="查看出現詞"> </p>
<h2 id="文字雲"><a href="#文字雲" class="headerlink" title="文字雲"></a>文字雲</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 文字雲</span><br><span class="line"># 計算詞彙的出現次數，如果詞彙只有一個字則不列入計算</span><br><span class="line">tokens_count &lt;- tokens %&gt;% </span><br><span class="line">  filter(nchar(.$word)&gt;1) %&gt;%</span><br><span class="line">  group_by(word) %&gt;% </span><br><span class="line">  summarise(sum = n()) %&gt;% </span><br><span class="line">  filter(sum&gt;10) %&gt;%</span><br><span class="line">  arrange(desc(sum))</span><br><span class="line">head(tokens_count, 30)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/R/SMA/2-%E5%87%BA%E7%8F%BE%E6%9C%80%E5%A4%9A%E7%9A%84%E5%89%8D30%E5%80%8B%E8%A9%9E.png?raw=true" alt="出現前30的詞"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tokens_count %&gt;% </span><br><span class="line">  filter(word!=c(&quot;比特幣&quot;,&quot;原文&quot;))%&gt;%</span><br><span class="line">#  wordcloud2()</span><br></pre></td></tr></table></figure>

<h2 id="詞性的標註（NER）"><a href="#詞性的標註（NER）" class="headerlink" title="詞性的標註（NER）"></a>詞性的標註（NER）</h2><p>那麼如果我們想知道裡面的名詞都有哪些？</p>
<p>我們就需要更改worker()中type的參數，改為worker(type=”tag”)，就可以用jieba來標記中文的詞性了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 初始化詞性標註引擎</span><br><span class="line">tag_cuter &lt;- worker(type=&quot;tag&quot;, stop_word=&quot;./stop_words.txt&quot;,user=&quot;./user_dict.txt&quot;) </span><br><span class="line"></span><br><span class="line">raw_text &lt;- &quot;在狗狗幣的市場中有一隻巨鯨持有著30%的狗狗幣，有一些線索指出這個持有者很有可能就是馬斯克&quot;</span><br><span class="line">look &lt;- segment(raw_text, tag_cuter)</span><br><span class="line"></span><br><span class="line"># 標註詞性的斷詞函式</span><br><span class="line">get_noun = function(x)&#123;</span><br><span class="line">  index = names(x) %in% c(&quot;n&quot;,&quot;nr&quot;,&quot;nr1&quot;,&quot;nr2&quot;,&quot;nrj&quot;,&quot;nrf&quot;,&quot;ns&quot;,&quot;nsf&quot;,&quot;nt&quot;,&quot;nz&quot;,&quot;nl&quot;,&quot;ng&quot;)</span><br><span class="line">  x[index]</span><br><span class="line">&#125;</span><br><span class="line">get_noun(look)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/R/SMA/2-%E8%A9%9E%E6%80%A7%E7%9A%84%E6%A8%99%E8%A8%BB.png?raw=true" alt="詞性的標註"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 自定義斷詞函式</span><br><span class="line">tag_tokenizer &lt;- function(t) &#123;</span><br><span class="line">  lapply(t, function(x) &#123;</span><br><span class="line">    tokens &lt;- segment(x, tag_cuter)</span><br><span class="line">    tokens &lt;- tokens[nchar(tokens)&gt;1]</span><br><span class="line">    return(paste(tokens,names(tokens))) # 將詞性和詞合併在一個欄位中，後面會再分開</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 將全文用標註詞性的斷詞函式斷開</span><br><span class="line">tag_tokens &lt;- MetaData %&gt;% </span><br><span class="line">  unnest_tokens(word, sentence, token=tag_tokenizer)</span><br><span class="line">str(tag_tokens)</span><br><span class="line"></span><br><span class="line"># 將詞和詞性分割成 2 欄，並新增至 Data Frame 中</span><br><span class="line">new_df &lt;- separate(tag_tokens, word, c(&quot;word&quot;, &quot;tag&quot;), &quot; &quot;)</span><br><span class="line"></span><br><span class="line"># 篩選出所有的名詞</span><br><span class="line">new_df_n &lt;- new_df %&gt;%</span><br><span class="line">  filter(tag %in% c(&quot;n&quot;,&quot;nr&quot;,&quot;nr1&quot;,&quot;nr2&quot;,&quot;nrj&quot;,&quot;nrf&quot;,&quot;ns&quot;,&quot;nsf&quot;,&quot;nt&quot;,&quot;nz&quot;,&quot;nl&quot;,&quot;ng&quot;))</span><br><span class="line">  # filter(tag == &quot;x&quot;)</span><br><span class="line">head(new_df_n)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/R/SMA/%E7%AF%A9%E9%81%B8%E5%87%BA%E7%9A%84%E6%89%80%E6%9C%89%E5%90%8D%E8%A9%9E.png?raw=true" alt="篩選出的所有名詞"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 計算每個詞出現的次數</span><br><span class="line">tokens_count &lt;- new_df_n %&gt;% </span><br><span class="line">  filter(nchar(.$word)&gt;1) %&gt;%</span><br><span class="line">  group_by(word) %&gt;% </span><br><span class="line">  summarise(sum = n()) %&gt;% </span><br><span class="line">  filter(sum&gt;10) %&gt;%</span><br><span class="line">  arrange(desc(sum))</span><br><span class="line"></span><br><span class="line"># 查看看出現最多的前20個名詞</span><br><span class="line">head(tokens_count,20)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/R/SMA/2-%E6%9F%A5%E7%9C%8B%E5%90%8D%E8%A9%9E%E7%9A%84%E5%89%8D20.png?raw=true" alt="查看名詞的前20"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 畫出文字雲</span><br><span class="line">tokens_count %&gt;% </span><br><span class="line">  filter(word!=c(&quot;比特幣&quot;,&quot;價格&quot;))%&gt;%</span><br><span class="line">  top_n(20)%&gt;%</span><br><span class="line">  wordcloud2()</span><br><span class="line">  </span><br><span class="line"># “原文”是ptt中出現格式詞彙，應該去掉。</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/R/SMA/2-%E6%96%87%E5%AD%97%E9%9B%B2.png?raw=true" alt="文字雲"></p>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>courses</tag>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title>有關 Data mining 的一點反思</title>
    <url>/%E6%9C%89%E9%97%9C%20Data%20mining%20%E7%9A%84%E4%B8%80%E9%BB%9E%E5%8F%8D%E6%80%9D/</url>
    <content><![CDATA[<p>寫這篇的起因，就是最近幾節課課的期中報告都是Data mining相關的project。</p>
<h1 id="工具🔨-vs-目的🚩"><a href="#工具🔨-vs-目的🚩" class="headerlink" title="工具🔨 vs 目的🚩"></a>工具🔨 vs 目的🚩</h1><p>美國作家馬克·吐溫有句名言，說：“如果你身上唯一的工具是一把錘子，那麼你會把所有的問題都看成釘子。”美國著名投資家查理·芒格，根據馬克·吐溫的這句話，將這種現象稱為“拿錘子的人”——芒格分析說，人們經過年復一年的專業培訓，會成為經濟學家、工程師、營銷經理、投資經理等等。一旦當他們瞭解並熟悉某一個領域的思維模式之後，他們就會到處嘗試將所有遇到的問題，都用自己的專業思維模式來解決。</p>
<p>我們在學習的時候也會有這種問題，像是這學期的社群媒體分析的課上學習了一些nlp的知識以及工具，像是“情緒分析”，“關係網絡”，“n-grams”等。就使得在分析某個議題的時候，我們就會很自然的直接套用這些分析工具，無論是否必要。</p>
<p>這就引出最近我在做 Data mining 的時候幾點反思：</p>
<h2 id="我們分析的目的是什麼？"><a href="#我們分析的目的是什麼？" class="headerlink" title="我們分析的目的是什麼？"></a>我們分析的目的是什麼？</h2><p>很多時候我們甚至都還沒明確分析的目的，只是有一個現成的資料集，就開始按照流程來套工具🔧。把一個資料集用額種各樣工具處理完之後，再來從一堆結果中找有什麼值得探討和解釋的points。這其實是一個很本末倒置的過程。我們的分析應該是為我們的目的服務的，而不是從結果中隨意得出幾個結論。</p>
<p>所以在開始一些列分析的步驟前一定要先釐清我們的目標：</p>
<ul>
<li>我們最主要分析的問題是什麼？（what？How？）</li>
<li>這個問題的合理性以及意義所在？</li>
<li>圍繞這個問題我們能從那些方面展開討論？</li>
</ul>
<p>我們也可以借助一些工具來幫助我們展開我們要分析的問題，釐清我們要分析的目標：</p>
<ul>
<li>問題樹</li>
<li>⋯⋯</li>
</ul>
<p>總之多花些時間在釐清分析的目的會便於我們後續運用更合適的工具，得到我們想要的結果。不會做著做著突然突然迷失在一堆資料中，開始懷疑自己到底在幹嘛。</p>
<h2 id="工具是否合適？"><a href="#工具是否合適？" class="headerlink" title="工具是否合適？"></a>工具是否合適？</h2><p>釐清問題之後我們就可以選擇合適的分析工具了。工具的何時與否還是要看我們分析的目的是什麼。</p>
<h2 id="分析結果的評估？"><a href="#分析結果的評估？" class="headerlink" title="分析結果的評估？"></a>分析結果的評估？</h2><h3 id="模型的評估"><a href="#模型的評估" class="headerlink" title="模型的評估"></a>模型的評估</h3><p>模型的評估，在Data mining中對於分類和回歸問題都有很多不同的評估方式（Accuracy，F1-score，SSE，MSE⋯⋯），但是具體問題要具體分析，找到合適的評估指標。用錯了評估指標就會出現，像是Accuracy很高，但是模型並不fit的情況。</p>
<h3 id="結果的評估"><a href="#結果的評估" class="headerlink" title="結果的評估"></a>結果的評估</h3><p>結果的評估分為很多個方面，首先我們要看是不是有符合我們想要分析的目標。</p>
<p>如果沒有得到我們預期的結果是什麼原因：</p>
<ul>
<li>資料本身的屬性，並不能很好的解決我們的問題（要不要多加入一些資料）</li>
<li>是不是資料的前處理有問題（像是feature的篩選、data imbalance的處理、斷詞、專業領域的lexicon的選擇等）</li>
<li>工具的選擇有些問題（有些資料可能不適合用樹的模型做分類）</li>
</ul>
<h1 id="化繁為簡"><a href="#化繁為簡" class="headerlink" title="化繁為簡"></a>化繁為簡</h1><p>以前考試只覺得煎熬，想著怎麼在考前最短的時間拿到還不錯的成績，然後考完就可以就瞬間把所有知識忘掉。</p>
<p>最近開始意識到其實考試是一個很好的化繁為簡的過程，而且是有人幫助你將重點的知識歸納出來。</p>
<p>其實複習已經是一個強迫自己梳理知識歸納總結的過程了，但是透過考試我們能更好的找出自己梳理的重點，和老師想在這節課傳達的重點之間的差距。從而補足自己這節課上的知識漏洞。意識到這一點之後，其實分數已經沒那麼重要了，重要的是歸納梳理的過程，以及考試之後對於自己知識漏洞的補足。</p>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>courses</tag>
      </tags>
  </entry>
  <entry>
    <title>豆瓣爬蟲-2｜lxml 的介紹</title>
    <url>/%E8%B1%86%E7%93%A3%E7%88%AC%E8%9F%B2-2%EF%BD%9Clxml%20%E7%9A%84%E4%BB%8B%E7%B4%B9/</url>
    <content><![CDATA[<h2 id="lxml介紹"><a href="#lxml介紹" class="headerlink" title="lxml介紹"></a>lxml介紹</h2><p>Python的lxml 模組是一個非常好用且效能高的HTML、XML解析工具，通過它解析網頁，爬蟲就可以輕鬆的從網頁中提取想要的資料。lxml對XML和HTML都有很好的支援，分別使用 lxml.etree 和 lxml.html 兩個模組。</p>
<h2 id="使用lxml提取網頁資料的流程"><a href="#使用lxml提取網頁資料的流程" class="headerlink" title="使用lxml提取網頁資料的流程"></a>使用lxml提取網頁資料的流程</h2><p>要從網頁裡面提取資料，使用lxml需要兩步：</p>
<ul>
<li>第一步，用lxml把網頁（或xml）解析成一個DOM樹。這個過程，我們可以選擇<code>etree</code>、<code>etree.HTML</code>和 <code>lxml.html</code>這三種來實現，它們基本類似但又有些許差別。</li>
<li>第二步，使用<code>xpath</code>遍歷這棵DOM 樹，找到你想要的資料所在的節點並提取。這一步要求我們對xpath規則比較熟練，xpath規則很多，但別怕，我來總結一些常用的套路。</li>
</ul>
<h3 id="生成DOM樹"><a href="#生成DOM樹" class="headerlink" title="生成DOM樹"></a>生成DOM樹</h3><p>上面我們說了，可以有三種方法來把網頁解析成DOM樹，那麼我們選擇哪一種呢？</p>
<p>一般HTML網頁用這個比較多：<code>etree.HTML(html)</code>和<code>lxml.html(html)</code></p>
<h4 id="🌟etree-HTML-html"><a href="#🌟etree-HTML-html" class="headerlink" title="🌟etree.HTML(html)"></a>🌟etree.HTML(html)</h4><p>我們可以用這個：<code>print(etree.tostring(etree.HTML(html)).decode())</code>來將dom樹還原成之前的html，我們可以發現<code>etree.HTML()</code>函式會補全html程式碼片段，給它們加上<code>&lt;html&gt;</code>和<code>&lt;body&gt;</code>標籤。</p>
<h4 id="🌟lxml-html-html"><a href="#🌟lxml-html-html" class="headerlink" title="🌟lxml.html(html)"></a>🌟lxml.html(html)</h4><p>lxml.html是lxml的子模組，它是對etree的封裝，更適合解析html網頁。生成DOM樹的方法有多個：</p>
<ul>
<li>lxml.html.document_fromstring()</li>
<li>lxml.html.fragment_fromstring()</li>
<li>lxml.html.fragments_fromstring()</li>
<li>lxml.html.fromstring()</li>
</ul>
<p>我們解析網頁用最後一個fromstring()即可。</p>
<h3 id="使用xpath提取資料"><a href="#使用xpath提取資料" class="headerlink" title="使用xpath提取資料"></a>使用xpath提取資料</h3><p>以下面一段簡單的html為例，來介紹一下xpath對資料的提取：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"1"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"p_1 item"</span>&gt;</span>item_1<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"p_2 item"</span>&gt;</span>item_2<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"2"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">"p3"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/go-p3"</span>&gt;</span>item_3<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol>
<li>首先生成DOM樹：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree </span><br><span class="line">doc = etree.HTML(html)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>通過標籤屬性定位節點:比如我們要獲取<code>&lt;div class=&quot;2&quot;&gt;</code>這節點：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">doc.xpath(<span class="string">'//div[@class="2"]'</span>)</span><br><span class="line">print(etree.tostring(doc.xpath(<span class="string">'//div[@class="2"]'</span>)[<span class="number">0</span>]).decode())</span><br><span class="line"><span class="comment"># &lt;div class="2"&gt;</span></span><br><span class="line"><span class="comment">#     &lt;p id="p3"&gt;&lt;a href="/go-p3"&gt;item_3&lt;/a&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="comment"># &lt;/div&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>contains語法</li>
</ol>
<p>html中有兩個<code>&lt;p&gt;</code>標籤的class含有<code>item</code>，如果我們要提取這兩個<code>&lt;p&gt;</code>標籤，則：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 獲取&lt;p&gt;的文字：</span></span><br><span class="line">doc.xpath(<span class="string">'//p[contains(@class, "item")]/text()'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt;&gt; ['item_1', 'item_2']</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>starts-with語法</li>
</ol>
<p>一樣的提取需求，兩個<code>&lt;p&gt;</code>標籤的class都是以p_開頭的，所以:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 獲取&lt;p&gt;的文字：</span></span><br><span class="line">doc.xpath(<span class="string">'//p[starts-with(@class, "p_")]/text()'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt;&gt; ['item_1', 'item_2']</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>獲取某一屬性的值</li>
</ol>
<p>比如，我們想提取網頁中所有的連結：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">doc.xpath(<span class="string">'//@href'</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>lxml</tag>
        <tag>spider</tag>
      </tags>
  </entry>
  <entry>
    <title>豆瓣爬蟲-1｜selenium 的介紹</title>
    <url>/%E8%B1%86%E7%93%A3%E7%88%AC%E8%9F%B2-1%EF%BD%9Cselenium%20%E7%9A%84%E4%BB%8B%E7%B4%B9/</url>
    <content><![CDATA[<p>紀錄一下寫豆瓣爬蟲的過程和一些心得</p>
<h2 id="selenium-的介紹"><a href="#selenium-的介紹" class="headerlink" title="selenium 的介紹"></a>selenium 的介紹</h2><p>selenium 是一款自動化測試利器，可以自動化模擬人的瀏覽器操作行為，所以也可以用於網絡爬蟲。<br>不過這裡主要講一講怎樣用selenium來模擬登錄，並持久化cookie，然後用requests爬取頁面。</p>
<h2 id="selenium-的安装及配置"><a href="#selenium-的安装及配置" class="headerlink" title="selenium 的安装及配置"></a>selenium 的安装及配置</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>直接安裝 selenium </p>
<p><code>pip install selenium</code></p>
<h3 id="配置-webdriver"><a href="#配置-webdriver" class="headerlink" title="配置 webdriver"></a>配置 webdriver</h3><p>使用 selenium 前我們首先要配置浏览器的 webdriver 這邊主要提供3種常用瀏覽器的配置頁面：</p>
<ul>
<li><a href="https://sites.google.com/a/chromium.org/chromedriver/downloads" target="_blank" rel="noopener">chrome</a></li>
<li><a href="https://github.com/mozilla/geckodriver/releases" target="_blank" rel="noopener">Firefox</a></li>
<li><a href="https://webkit.org/blog/6900/webdriver-support-in-safari-10/" target="_blank" rel="noopener">Safari</a></li>
</ul>
<p>⚠️ 下載前一定要查看一下自己瀏覽器的版本，下載適配版本的 webdriver</p>
<h3 id="配置-chromedriver（Mac版本）"><a href="#配置-chromedriver（Mac版本）" class="headerlink" title="配置 chromedriver（Mac版本）"></a>配置 chromedriver（Mac版本）</h3><p>以chromedriver為例，在下載好後，我們將 chromedriver 檔案放入到：/usr/local/bin/ 這個路徑下面。</p>
<p>具體的步驟：打開一個 Finder -&gt; shift+command+G -&gt; 輸入路徑 /usr/local/bin/ 按下return -&gt; 將 chromedriver 放入</p>
<p>⚠️ 可能會遇到的error：</p>
<p>“chromedriver” cannot be opened because the developer cannot be verified. Unable to launch the chrome browser on Mac OS</p>
<p>解決辦法可以看這個<a href="https://timonweb.com/misc/fixing-error-chromedriver-cannot-be-opened-because-the-developer-cannot-be-verified-unable-to-launch-the-chrome-browser-on-mac-os/" target="_blank" rel="noopener">Blog</a>按照上面的步驟輸入就可以正常運行了。</p>
<h2 id="selenium-的一些基本用法"><a href="#selenium-的一些基本用法" class="headerlink" title="selenium 的一些基本用法"></a>selenium 的一些基本用法</h2><p>控制瀏覽器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Chrome() <span class="comment"># 需要調用對應的chromedriver.exe</span></span><br></pre></td></tr></table></figure>

<p>使用IP代理，通常不需要都行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chrome_option = webdriver.ChromeOptions()</span><br><span class="line">chrome_option.add_argument(<span class="string">'--proxy--server=112.84.55.122:9999'</span>)<span class="comment">#使用代理IP</span></span><br></pre></td></tr></table></figure>

<p>等待網頁加載</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.implicitly_wait(<span class="number">5</span>) <span class="comment">#最長等待5秒，記載完成後自動跳過</span></span><br></pre></td></tr></table></figure>

<p>打開網頁</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.get(url) <span class="comment"># 需要打開的網頁</span></span><br></pre></td></tr></table></figure>

<p>點擊網頁節點</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.find_element_by_xpath(<span class="string">'這裡放網頁xpath路徑'</span>).click()</span><br></pre></td></tr></table></figure>

<p>輸入內容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.find_element_by_xpath(<span class="string">'這裡放網頁輸入框的xpath路徑'</span>).send_keys(<span class="string">'輸入詞'</span>)</span><br></pre></td></tr></table></figure>

<p>獲取文本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">driver.find_element_by_xpath(<span class="string">'網頁中文本xpath路徑'</span>).text <span class="comment">#直接獲取某個具體文本</span></span><br></pre></td></tr></table></figure>

<p>網頁下拉</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">js=<span class="string">"var q=document.documentElement.scrollTop=10000000"</span> <span class="comment">#滾動條，數值為每次下拉的長度，不疊加，以瀏覽器底部為最大值</span></span><br><span class="line">driver.execute_script(js)<span class="comment">#調用js</span></span><br></pre></td></tr></table></figure>

<h2 id="使用-selenium-模擬豆瓣登錄的-demo"><a href="#使用-selenium-模擬豆瓣登錄的-demo" class="headerlink" title="使用 selenium 模擬豆瓣登錄的 demo"></a>使用 selenium 模擬豆瓣登錄的 demo</h2><p>因為selenium是模擬人的一個登錄的行為，所以首先要釐清一下我們在做登錄時的一個邏輯：</p>
<ol>
<li>打開瀏覽器</li>
<li>打開url</li>
<li>在“短信登錄”和“密碼登錄”中選擇“密碼登錄”（因為短信登錄會有經常報錯的問題）</li>
<li>定位到“帳號”和“密碼”（查看wed的html文檔）</li>
<li>輸入“帳號”和“密碼”</li>
<li>點擊“登錄豆瓣”</li>
</ol>
<p>需要import的模塊主要就是兩個：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下來就是定義登錄的函數</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        登錄，並持久化cookie</span></span><br><span class="line"><span class="string">        :return: None</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># 豆瓣登錄頁面 URL</span></span><br><span class="line">        login_url = <span class="string">'https://www.douban.com/accounts/login'</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 獲取chrome的配置</span></span><br><span class="line">        opt = webdriver.ChromeOptions()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在運行的時候不彈出瀏覽器窗口</span></span><br><span class="line">        <span class="keyword">if</span> self.headless:</span><br><span class="line">            opt.set_headless()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 獲取driver對象</span></span><br><span class="line">        self.driver = webdriver.Chrome(chrome_options = opt)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 打開登錄頁面</span></span><br><span class="line">        self.driver.get(login_url)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'[login] opened login page...'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 向瀏覽器發送用戶名、密碼，並點擊登錄按鈕</span></span><br><span class="line">        <span class="comment"># 首先點擊“密碼登錄”，從手機號登陸轉到密碼登錄（因為手機號會區域登陸異常的問題）</span></span><br><span class="line">        self.driver.find_element_by_class_name(<span class="string">'account-tab-account'</span>).click()</span><br><span class="line">        <span class="comment"># 用 clear()清空一下之前的用戶名和密碼，然後用 send_keys()發送一下用戶名和密碼</span></span><br><span class="line">        self.driver.find_element_by_name(<span class="string">'username'</span>).clear()</span><br><span class="line">        self.driver.find_element_by_name(<span class="string">'username'</span>).send_keys(self.user_name)</span><br><span class="line">        self.driver.find_element_by_name(<span class="string">'password'</span>).clear()</span><br><span class="line">        self.driver.find_element_by_name(<span class="string">'password'</span>).send_keys(self.password)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 多次登錄需要輸入驗證碼，這裡給一個手工輸入驗證碼的時間</span></span><br><span class="line">        <span class="comment"># 等待 3 秒鐘</span></span><br><span class="line">        time.sleep(<span class="number">3</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定位到“登錄按鈕”超鏈接信息上面的文本元素</span></span><br><span class="line">        self.driver.find_element_by_link_text(<span class="string">'登錄豆瓣'</span>).click()</span><br><span class="line">        print(<span class="string">'[login] submited...'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 等待 3 秒鐘</span></span><br><span class="line">        time.sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 推出 自動關閉</span></span><br><span class="line">        driver.quit()</span><br></pre></td></tr></table></figure>

<p>👆就完成了一個簡單的用戶登入的行為</p>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>spider</tag>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title>文字探勘-1｜資料倫理與分析陷阱</title>
    <url>/%E6%96%87%E5%AD%97%E6%8E%A2%E5%8B%98-1%EF%BD%9C%E8%B3%87%E6%96%99%E5%80%AB%E7%90%86%E8%88%87%E5%88%86%E6%9E%90%E9%99%B7%E9%98%B1/</url>
    <content><![CDATA[<h2 id="簡介"><a href="#簡介" class="headerlink" title="簡介"></a>簡介</h2><p>“社媒”這一系列主要用以梳理“社群媒體分析”這堂課的知識點以及紀錄一些課後的思考🤔。</p>
<h2 id="資料倫理"><a href="#資料倫理" class="headerlink" title="資料倫理"></a>資料倫理</h2><h2 id="🌰-Case-Automated-Health-Care-App"><a href="#🌰-Case-Automated-Health-Care-App" class="headerlink" title="🌰 Case: Automated Health Care App"></a>🌰 Case: Automated Health Care App</h2><p>來源：<a href="https://aiethics.princeton.edu/case-studies/case-study-pdfs/" target="_blank" rel="noopener">https://aiethics.princeton.edu/case-studies/case-study-pdfs/</a></p>
<p>簡介：Charlie 是一款智能健康管理的app</p>
<ul>
<li>利用只會手錶來監測患者的血糖</li>
<li>利用AI演算法，來計算藥劑的注射量，以及生活型態的建議</li>
<li>並設置論壇（furom）來供病友互相交流，並且提供最新的資訊。</li>
</ul>
<h3 id="舊版："><a href="#舊版：" class="headerlink" title="舊版："></a>舊版：</h3><p>⚠️ 面臨的問題：</p>
<ul>
<li>雖然大部分使用者對降低血糖都有作用，但是少數族裔，和少部分一些人並沒有改善</li>
<li>在論壇中出現了同溫層現象，並互相攻擊</li>
<li>有一些人離開了</li>
</ul>
<p>上述👆問題的分析：</p>
<ul>
<li>問題1：少數族裔沒有效果很可能是，他們的資料量太小，沒有足夠的資料來建立模型，來給這一部分人群提供比較完善的醫療方案。<ul>
<li>我的一些小困惑 😖<ul>
<li>差異化的模型？？</li>
<li>所以這種模型要怎麼訓練？？</li>
<li>是不是只有應用之後才能知道不適合所有人，從而做出差異化的模型？？</li>
<li>前期的數據探索是否能看出一些端倪？？</li>
<li>所以是不是只要數據夠多，模型就可以cover這種差異化？？）</li>
</ul>
</li>
</ul>
</li>
<li>問題2：人喜歡看符合自己價值觀的</li>
</ul>
<p>解決方案：</p>
<ul>
<li>問題1：<ul>
<li>收集更多少數族裔的資料</li>
</ul>
</li>
<li>問題2：<ul>
<li>減少病人接觸非主流的報導</li>
<li>同溫層：不按時間次序顯示文章和留言；被讚較多的優先</li>
</ul>
</li>
<li>問題3：<ul>
<li>個性化推薦文章，使用（MAB）</li>
</ul>
</li>
</ul>
<h3 id="新版："><a href="#新版：" class="headerlink" title="新版："></a>新版：</h3><p>運行結果：基本解決上述的3個問題</p>
<p>⚠️ 但是！一些人產生了擔憂：</p>
<ul>
<li>文章遭到公司的過濾，替病友決定了什麼是該看的文章（家長式領導Paternalism）</li>
<li>MAB的推薦系統的文章可能對病友造成傷害</li>
<li>Charlie演算法運作機制不明，缺乏透明度</li>
</ul>
<p>團隊的反饋：</p>
<ul>
<li>文章的過濾基於的是醫學專業的考量</li>
<li>MAB推薦的文章都是經過認證的</li>
<li>AI雖有黑箱的問題，但是人類專家得出結論，一般病人也不會詢問醫生是如何判斷的。</li>
</ul>
<h2 id="資料分析的陷阱"><a href="#資料分析的陷阱" class="headerlink" title="資料分析的陷阱"></a>資料分析的陷阱</h2><p>資料分析常常被拿來誤導：</p>
<ul>
<li>誤導可以帶來利益</li>
<li>誤導的信息傳播的特別快</li>
<li>人類的同理心可以產生完美的誤導</li>
</ul>
<p>誤導產生的面向：</p>
<ul>
<li>人本身：<ul>
<li>人本身跟偏愛和自己立場一致的文章：很可能並不會看完文章的，判斷對錯，只是因為立場一致而就進一步傳播</li>
<li>同溫層的產生</li>
</ul>
</li>
<li>機器的誘導：<ul>
<li>演算法為增加用戶黏性而一直只推薦用戶喜歡的文章：使用戶只能看到和自己立場相似的文章，而看不到客觀的事實。</li>
</ul>
</li>
<li>結果的呈現：<ul>
<li>修改圖表的scale從而達到表達自己想要的結論的目的。</li>
<li>相關性常被誤導為因果關係</li>
<li>觀察的偏差：觀察角度的不同可能會有完全不一樣的結論（如何避免呢？？？）</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>courses</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB 的載入</title>
    <url>/MongoDB%20%E7%9A%84%E8%BC%89%E5%85%A5/</url>
    <content><![CDATA[<h2 id="安装MongoDB"><a href="#安装MongoDB" class="headerlink" title="安装MongoDB"></a>安装MongoDB</h2><p>安裝 Mongo3.2</p>
<p>Windows：<a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-on-windows/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/tutorial/install-mongodb-on-windows/</a></p>
<p>Mac OS：<a href="https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/</a></p>
<p>安裝 Studio 3T（MongoDB的可視化工具）</p>
<p><a href="https://robomongo.org/" target="_blank" rel="noopener">https://robomongo.org/</a></p>
<h2 id="將資料匯入Studio-3T"><a href="#將資料匯入Studio-3T" class="headerlink" title="將資料匯入Studio 3T"></a>將資料匯入Studio 3T</h2><h3 id="Create-database"><a href="#Create-database" class="headerlink" title="Create database"></a>Create database</h3><p><img src="https://github.com/skyexx/skyexx.github.io/blob/master/image/MongoDB/MongoDB_1.png?raw=true" alt="GitHub"> </p>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>mongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Github 圖床測試</title>
    <url>/article/</url>
    <content><![CDATA[<h2 id="this-is-test"><a href="#this-is-test" class="headerlink" title="this is test"></a>this is test</h2><p><img src="https://img-blog.csdnimg.cn/20200311110734967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="file"></p>
]]></content>
      <categories>
        <category>Commercial</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>R｜資料的預處理：刪減不需要的資料</title>
    <url>/R%EF%BD%9C%E8%B3%87%E6%96%99%E7%9A%84%E9%A0%90%E8%99%95%E7%90%86%EF%BC%9A%E5%88%AA%E6%B8%9B%E4%B8%8D%E9%9C%80%E8%A6%81%E7%9A%84%E8%B3%87%E6%96%99/</url>
    <content><![CDATA[<p>R的資料處理很常用的package“dplyr” 裡面select()常被用來做資料的刪減</p>
<h1 id="select-的用法"><a href="#select-的用法" class="headerlink" title="select() 的用法"></a>select() 的用法</h1><p>以mtcars資料集為例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">head(mtcars,3)</span><br><span class="line">#                    mpg cyl disp  hp drat    wt  qsec vs am gear carb</span><br><span class="line"># Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4</span><br><span class="line"># Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4</span><br><span class="line"># Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1</span><br></pre></td></tr></table></figure>

<p>刪減不需要的資料欄位<br>假設不需要用到 mpy，hp這兩個欄位</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mtcars1=select(mtcars,-c(&quot;mpg&quot;,&quot;hp&quot;))</span><br><span class="line">head(mtcars1,3)</span><br><span class="line">#                   cyl disp drat    wt  qsec vs am gear carb</span><br><span class="line"># Mazda RX4           6  160 3.90 2.620 16.46  0  1    4    4</span><br><span class="line"># Mazda RX4 Wag       6  160 3.90 2.875 17.02  0  1    4    4</span><br><span class="line"># Datsun 710          4  108 3.85 2.320 18.61  1  1    4    1</span><br></pre></td></tr></table></figure>

<p>假設需要mpg到wt的資料,但是不需要cyl和hp這兩個欄位</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mtcars2=select(mtcars,mpg:wt,-c(&quot;cyl&quot;,&quot;hp&quot;))</span><br><span class="line">head(mtcars2,3)</span><br><span class="line">#                mpg disp drat    wt</span><br><span class="line"># Mazda RX4     21.0  160 3.90 2.620</span><br><span class="line"># Mazda RX4 Wag 21.0  160 3.90 2.875</span><br><span class="line"># Datsun 710    22.8  108 3.85 2.320</span><br></pre></td></tr></table></figure>

<h1 id="select-的子函數"><a href="#select-的子函數" class="headerlink" title="select() 的子函數"></a>select() 的子函數</h1><p>select 還有很多非常好用的子函數</p>
<ul>
<li>starts_with()；</li>
<li>ends_with()；</li>
<li>contains()；</li>
<li>matches()；</li>
<li>num_range()；</li>
<li>one_of()；</li>
<li>everything()</li>
</ul>
<p>找出欄位中所有以“c”開頭的columns</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mtcars3 = select(mtcars,starts_with(&quot;c&quot;))</span><br><span class="line">head(mtcars3,3)</span><br><span class="line">#               cyl carb</span><br><span class="line"># Mazda RX4       6    4</span><br><span class="line"># Mazda RX4 Wag   6    4</span><br><span class="line"># Datsun 710      4    1</span><br></pre></td></tr></table></figure>

<p>刪掉欄位名稱中有“ar”的columns</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mtcars4 = select(mtcars,-contains(&quot;ar&quot;))</span><br><span class="line">head(mtcars4,3)</span><br><span class="line"># 原始           mpg cyl disp  hp drat    wt  qsec vs am gear carb</span><br><span class="line">#                mpg cyl disp  hp drat    wt  qsec vs am</span><br><span class="line"># Mazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1</span><br><span class="line"># Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1</span><br><span class="line"># Datsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1</span><br></pre></td></tr></table></figure>

<p>可以看出“ar”是一整個的字符串，所以字母順序需要注意，有“ra”就被保留下來了</p>
<p>其他的幾個子函數的用法也類似starts_with()</p>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>details</tag>
        <tag>dplyr</tag>
      </tags>
  </entry>
  <entry>
    <title>R｜數據中缺失值-NA-的處理</title>
    <url>/R%EF%BD%9C%E6%95%B8%E6%93%9A%E4%B8%AD%E7%BC%BA%E5%A4%B1%E5%80%BC-NA-%E7%9A%84%E8%99%95%E7%90%86/</url>
    <content><![CDATA[<p>訓練一個機器學習模型，其實大量的時間是花在資料的預處理和探索性資料分析上。尤其是實際中遇到的data都不會太乾淨，所以花較長的時間來做數據的預處理是很有必要的。</p>
<p>首先來建立一個簡單的數據集</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(mice)</span><br><span class="line">name = c(&quot;Andy&quot;,&quot;Helly&quot;,&quot;Ann&quot;,&quot;Ketay&quot;,&quot;Wang&quot;,&quot;Liu&quot;)</span><br><span class="line">country = c(&quot;UK&quot;,&quot;US&quot;,&quot;US&quot;,&quot;US&quot;,&quot;CH&quot;,&quot;CH&quot;)</span><br><span class="line">gender = c(&quot;male&quot;,&quot;female&quot;,NA,&quot;female&quot;,&quot;male&quot;,NA)</span><br><span class="line">age = c(22,19,26,31,45,32)</span><br><span class="line">income = c(12,NA,55,77,32,NA)</span><br><span class="line"></span><br><span class="line">data = data.frame(name,country,gender,age,income)</span><br><span class="line">data</span><br><span class="line"># name country gender age income</span><br><span class="line"># 1  Andy      UK   male  22     12</span><br><span class="line"># 2 Helly      US female  19     NA</span><br><span class="line"># 3   Ann      US   &lt;NA&gt;  26     55</span><br><span class="line"># 4 Ketay      US female  31     77</span><br><span class="line"># 5  Wang      CH   male  45     32</span><br><span class="line"># 6   Liu      CH   &lt;NA&gt;  32     NA</span><br></pre></td></tr></table></figure>

<h2 id="查找NA"><a href="#查找NA" class="headerlink" title="查找NA"></a>查找NA</h2><ul>
<li><p>存在NA的rows</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">complete.cases(data) # 當一筆資料是完整的，回傳TRUE；當一筆資料有遺漏值，回傳FALSE</span><br><span class="line">#[1]  TRUE FALSE FALSE  TRUE  TRUE FALSE</span><br></pre></td></tr></table></figure>
</li>
<li><p>查找缺失值的位置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">which(is.na(data))  #返回缺失值的位置</span><br></pre></td></tr></table></figure>
</li>
<li><p>計算數據集中有缺失的資料筆數所佔比例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">loss = sum(is.na(data)) #計算資料集中的缺失值總數</span><br><span class="line">have = sum(complete.cases(data)) #統計資料集中完整樣本的個數</span><br><span class="line">ratio = loss/(loss+have) #計算缺失值資料的比重</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="填補NA"><a href="#填補NA" class="headerlink" title="填補NA"></a>填補NA</h2><ol>
<li><p>na.omit() 可以刪除所有含有缺失資料的row</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data1 = na.omit(data)</span><br><span class="line">data1</span><br><span class="line"># name country gender age income</span><br><span class="line"># 1  Andy      UK   male  22     12</span><br><span class="line"># 4 Ketay      US female  31     77</span><br><span class="line"># 5  Wang      CH   male  45     32</span><br></pre></td></tr></table></figure>
</li>
<li><p>最高頻率來填補缺失值.嘗試找到這些缺失值最可能的值。</p>
<blockquote>
<p>對於變數分佈近似正態分佈時可以選用平均值；偏態分佈一般採用中位數代表資料中心趨勢的指標。</p>
</blockquote>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mean_income = mean(data$income)</span><br><span class="line">data2 = data</span><br><span class="line">#一些函式計算時擁有na.rm=TRUE，可以在計算以前移除缺失值並使用剩餘值進行計算</span><br><span class="line">data2[is.na(data2$income),&quot;income&quot;] = mean(data2$income,na.rm = T) #用平均數補充income的缺失值</span><br><span class="line">data2</span><br><span class="line"># name country gender age income</span><br><span class="line"># 1  Andy      UK   male  22     12</span><br><span class="line"># 2 Helly      US female  19     44</span><br><span class="line"># 3   Ann      US   &lt;NA&gt;  26     55</span><br><span class="line"># 4 Ketay      US female  31     77</span><br><span class="line"># 5  Wang      CH   male  45     32</span><br><span class="line"># 6   Liu      CH   &lt;NA&gt;  32     44</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>函式centralImputation()可以用資料的中心趨勢值來填補資料集的所有缺失值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data3 = data</span><br><span class="line">data3$income &lt;- centralImputation(data3$income)</span><br></pre></td></tr></table></figure>
</li>
<li><p>通過變數的相關關係填補缺失值 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#函式cor()的功能是產生變數之間的相關值矩陣,引數use = &quot;complete.obs&quot;可以忽略含有NA的記錄</span><br><span class="line">cor(data[,c(&quot;age&quot;,&quot;income&quot;)],use = &quot;complete.obs&quot;) # =cor(data[,4:5],use = &quot;complete.obs&quot;)</span><br><span class="line"># age     income</span><br><span class="line"># age    1.00000000 0.07670152</span><br><span class="line"># income 0.07670152 1.00000000</span><br><span class="line">lm(age~income,data = data) </span><br><span class="line">#函式lm()可以用來獲取線性模型</span><br><span class="line">#可以使用上述線性關係計算變數的缺失值</span><br></pre></td></tr></table></figure>
</li>
<li><p>用K-Nearest Neighbours填補遺漏值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">require(DMwR)</span><br><span class="line">imputeData &lt;- knnImputation(data)</span><br></pre></td></tr></table></figure>

</li>
</ol>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>details</tag>
      </tags>
  </entry>
  <entry>
    <title>R｜建模範例分析</title>
    <url>/R%EF%BD%9C%E5%BB%BA%E6%A8%A1%E7%AF%84%E4%BE%8B%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="R建模範例分析"><a href="#R建模範例分析" class="headerlink" title="R建模範例分析"></a>R建模範例分析</h1><p>Regression analysis is widely used in statisitic, always  analysis the correlation among  different variables. </p>
<blockquote>
<p>這是一個非常簡單資料處理和建模的例子，主要是為了熟悉整個資料分析和建模的流程。其中有很多細節可以繼續展開。</p>
</blockquote>
<h2 id="讀取資料"><a href="#讀取資料" class="headerlink" title="讀取資料"></a>讀取資料</h2><p>大部分讀取資料，讀取excel檔一本需要轉成CSV檔來讀取。<br>這裡我們以 iris.csv 這個 CSV 檔案作為範例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 讀取 iris.csv</span><br><span class="line">my.iris.df &lt;- read.csv(&quot;iris.csv&quot;)</span><br></pre></td></tr></table></figure>

<p>如果自己的csv檔沒有放在目前的目錄中，可以使用絕對路徑來指定：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 使用絕對路徑</span><br><span class="line">my.iris.df &lt;- read.csv(&quot;D:\\iris.csv&quot;)</span><br></pre></td></tr></table></figure>

<p><strong>雙反斜線（\）</strong>在R中屬於特殊的跳脫字元，所以在撰寫絕對路徑的時候，凡是要輸入反斜線的地方，都要改為雙反斜線。</p>
<p>讀取資料完成後，為了方便查看大體量的資料可以用head（）來查看前面幾行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看 my.iris.df 的資料的前面20rows</span><br><span class="line">head(my.iris.df, 20)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>將csv表格讀進R之後個欄位若有空白或是特殊字元，會被自動替代為（.），它不會影響到資料，只是在變數指定的時候要使用新的名字</p>
</blockquote>
<h2 id="資料的預處理"><a href="#資料的預處理" class="headerlink" title="資料的預處理"></a>資料的預處理</h2><p>讀進去之後我們就需要更詳細的了解資料的內部結構：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看 my.iris.df 內部結構</span><br><span class="line">str(my.iris.df)</span><br></pre></td></tr></table></figure>

<p>str輸出的一個row就是一個變數的欄位，標示了變數名稱與類型，後面接的是實際的資料筆數。</p>
<p>檢查完資料的類型沒有什麼問題之後，我們需要處理資料中殘留的一些不乾淨的數據以及缺失值NA。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 檢查是否有 NA 的資料</span><br><span class="line">my.iris.df[!complete.cases(my.iris.df),]</span><br></pre></td></tr></table></figure>

<p>如果資料是完整的就會返回一個空的dataframe</p>
<h2 id="分析資料與繪圖"><a href="#分析資料與繪圖" class="headerlink" title="分析資料與繪圖"></a>分析資料與繪圖</h2><p>通常在開始分析資料之前，會先用 <strong>summary</strong> 看一下各個變數的基本統計量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看基本統計量</span><br><span class="line">summary(my.iris.df)</span><br></pre></td></tr></table></figure>

<p>當然光看數字肯定是非常不直觀的，繪圖會是一個查看各組數據相關性的好方法。這裡我們示範使用** ggplot2 與 GGally** 套件來畫圖的方法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 載入 ggplot2 與 GGally 套件</span><br><span class="line">library(ggplot2)</span><br><span class="line">library(GGally)</span><br></pre></td></tr></table></figure>

<p>使用 ggpairs 可畫出很漂亮的資料<strong>分佈矩陣圖</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 繪製資料分佈矩陣圖</span><br><span class="line">ggpairs(my.iris.df)</span><br></pre></td></tr></table></figure>

<p>如果只想畫出簡單的 <strong>XY 散佈圖</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 畫出 XY 散佈圖</span><br><span class="line">require(ggplot2)</span><br><span class="line">qplot(x = Petal.Length,</span><br><span class="line">      y = Petal.Width,</span><br><span class="line">      data = my.iris.df)</span><br></pre></td></tr></table></figure>

<p>如果想要比較不同的 Species 類別的 XY 散佈圖，可以用<strong>color</strong>區分出不同的species：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 畫出 XY 散佈圖，依據 Species 上色</span><br><span class="line">require(ggplot2)</span><br><span class="line">qplot(x = Petal.Length,</span><br><span class="line">      y = Petal.Width,</span><br><span class="line">      data = my.iris.df,</span><br><span class="line">      color = Species)</span><br></pre></td></tr></table></figure>

<h2 id="建立回歸模型"><a href="#建立回歸模型" class="headerlink" title="建立回歸模型"></a>建立回歸模型</h2><p>建立迴歸模型可以使用 <strong>lm</strong> 這個函數（lm 代表 linear models），假設我們想要拿 Sepal.Length 作為反應變數（也就是 Y），而 Sepal.Width、Petal.Length 與 Petal.Width 作為解釋變數（也就是 X），則可以執行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 建立迴歸模型</span><br><span class="line">iris.lm &lt;- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width,</span><br><span class="line">              data = my.iris.df)</span><br></pre></td></tr></table></figure>

<p>其中第一個參數放的就是所謂的公式（formula），它用來表示迴歸模型的一種表示法，中間的** ~ <strong>相當於迴歸公式的</strong>等號**，左邊的 Sepal.Length 就是 Y，而右邊放的三個變數則是 X。第二個參數 data 則是用來指定資料來源的 data frame。</p>
<p>建立好迴歸模型之後，可以使用 summary 查看模型配適的結果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看模型配適結果</span><br><span class="line">summary(iris.lm)</span><br></pre></td></tr></table></figure>

<p>結果為：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Call:</span><br><span class="line">lm(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width,</span><br><span class="line">    data = my.iris.df)</span><br><span class="line">Residuals:</span><br><span class="line">     Min       1Q   Median       3Q      Max</span><br><span class="line">-0.82816 -0.21989  0.01875  0.19709  0.84570</span><br><span class="line">Coefficients:</span><br><span class="line">             Estimate Std. Error t value Pr(&gt;|t|)</span><br><span class="line">(Intercept)   1.85600    0.25078   7.401 9.85e-12 ***</span><br><span class="line">Sepal.Width   0.65084    0.06665   9.765  &lt; 2e-16 ***</span><br><span class="line">Petal.Length  0.70913    0.05672  12.502  &lt; 2e-16 ***</span><br><span class="line">Petal.Width  -0.55648    0.12755  -4.363 2.41e-05 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><br><span class="line">Residual standard error: 0.3145 on 146 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.8586,    Adjusted R-squared:  0.8557</span><br><span class="line">F-statistic: 295.5 on 3 and 146 DF,  p-value: &lt; 2.2e-16</span><br></pre></td></tr></table></figure>

<p>從這份輸出的結果中，我們可以看出各個解釋變數的係數，若將整個模型寫出來就會像這樣：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sepal.Length = 0.65084 * Sepal.Width</span><br><span class="line">             + 0.70913 * Petal.Length</span><br><span class="line">             - 0.55648 * Petal.Width</span><br><span class="line">             + 1.856</span><br></pre></td></tr></table></figure>

<p>報表中的 Pr(&gt;|t|) 就是統計上的 p-value，以這裡的值來說，每一個係數都非常顯著。<br>R-squared 的值為 0.8586，Adjusted R-squared 的值為 0.8557，表示模型的配適情況不錯</p>
<h2 id="模型診斷"><a href="#模型診斷" class="headerlink" title="模型診斷"></a>模型診斷</h2><p>在配適完迴歸模型之後，接著要進行模型診斷，通常會先畫出幾張常用來診斷模型的圖，這裡我們用 ggfortify 這個套件來畫圖。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(ggfortify)</span><br><span class="line"># 畫出模型診斷用的圖</span><br><span class="line">autoplot(iris.lm)</span><br></pre></td></tr></table></figure>

<p>在理論上迴歸模型配適完成後，其<strong>殘差值（residual）</strong>必須符合<strong>常態性（normality）</strong>、<strong>獨立性（independence）</strong>以及<strong>變異數同質性（homogeneity of variance）</strong>三種假設，所以接下來要用三種檢定檢查這三個條件是否符合。</p>
<h3 id="殘差獨立性檢定"><a href="#殘差獨立性檢定" class="headerlink" title="殘差獨立性檢定"></a>殘差獨立性檢定</h3><p>獨立性檢定要使用到 car 這個套件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 殘差獨立性檢定</span><br><span class="line">require(car)</span><br><span class="line">durbinWatsonTest(iris.lm)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lag Autocorrelation D-W Statistic p-value</span><br><span class="line">  1     -0.03992126      2.060382   0.822</span><br><span class="line">Alternative hypothesis: rho != 0</span><br></pre></td></tr></table></figure>

<p>殘差獨立性檢定的 p-value 也非常高，所以也不拒絕虛無假設，亦即殘差值的獨立性假設是合理的。</p>
<h3 id="殘差變異數同質性檢定"><a href="#殘差變異數同質性檢定" class="headerlink" title="殘差變異數同質性檢定"></a>殘差變異數同質性檢定</h3><p>殘差的變異數同質性檢定可以使用 car 套件所提供的 ncvTest（）函數：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 殘差變異數同質性檢定</span><br><span class="line">require(car)</span><br><span class="line">ncvTest(iris.lm)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Non-constant Variance Score Test </span><br><span class="line">Variance formula: ~ fitted.values </span><br><span class="line">Chisquare = 4.448612    Df = 1     p = 0.03492962</span><br></pre></td></tr></table></figure>

<p>殘差變異數同質性檢定的 p-value 稍微偏小，以一般 95% 的信賴水準來說，是拒絕虛無假設的，也就是說殘差的變異數沒有符合同質性的假設，但是因為這個 p-value 並沒有非常小，所以證據並不是非常明確。</p>
<h2 id="預測"><a href="#預測" class="headerlink" title="預測"></a>預測</h2><p>在迴歸模型建立好之後，就可以利用這個模型來預測新的資料，假設我們收到一些新的觀測值（解釋變數 X）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 新觀測值</span><br><span class="line">new.iris &lt;- data.frame(Sepal.Width=3.1, Petal.Length=1.6, Petal.Width=0.3)</span><br><span class="line">new.iris</span><br></pre></td></tr></table></figure>

<p>若要使用迴歸模型預測新的反應變數，可以使用 predict 函數</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 預測資料</span><br><span class="line">predict(iris.lm, new.iris)</span><br></pre></td></tr></table></figure>

<pre><code>1 </code></pre><p>4.841259<br>預測出來的 Sepal.Length 值就是 4.841259。</p>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>regression</tag>
      </tags>
  </entry>
  <entry>
    <title>Pwc性格測試</title>
    <url>/Pwc%E6%80%A7%E6%A0%BC%E6%B8%AC%E8%A9%A6/</url>
    <content><![CDATA[<h1 id="緣起"><a href="#緣起" class="headerlink" title="緣起"></a>緣起</h1><p>因為想找個分析類 winter internship 所以投了pwc，很快就接到了筆試的郵件。今年的筆試其實還挺有意思的，從原有的單純智商測試題，變為了互動性比較強的遊戲，不過感覺內容其實變化不大，不過趣味性確實比較強。遊戲通關後會有一個性格測試的報告，其實不管之後會不會接到 interview 的面試，這份報告，對於未來的成長和自我反思還是很有參考價值的。</p>
<h1 id="報告的內容"><a href="#報告的內容" class="headerlink" title="報告的內容"></a>報告的內容</h1><h2 id="個人風格"><a href="#個人風格" class="headerlink" title="個人風格"></a>個人風格</h2><p>相對於比較組，你的反應表明在解讀情緒和麵部表情方面，你的準確度趨向於非常高。</p>
<h2 id="認知"><a href="#認知" class="headerlink" title="認知"></a>認知</h2><p>你傾向於加工信息量較小的信息，對於處理信息量較大的信息你的自信程度會比較低<br>加工信息的速度屬於平均水平</p>
<h2 id="驅動力"><a href="#驅動力" class="headerlink" title="驅動力"></a>驅動力</h2><p>（這個結果很有意思，讓我有點意想不到）</p>
<ul>
<li>相對於比較組，你的反應表明你相當有可能需要<strong>花較長的時間來從挫折中恢復</strong>。同時在<strong>逆境之下</strong>，你在相當程度上更有可能<strong>難以保持對目標的專注</strong>。</li>
<li>相對於比較組，你的注意力會平均地受你的價值觀、目標、想法、感覺和生理狀態影響。</li>
<li>相對於比較組，你的反應表明你在很大程度上傾向於更願意出力來完成所想要達成的結果，以獲得內在或外在的獎勵。</li>
</ul>
<blockquote>
<p>確實在面對逆境的時候我很容易把自己的生活搞的混亂不堪，然後花很長的時間從這片泥沼中慢慢爬起來。明白也許逆境是生活的常態，學會勇敢的面對挫折，不要把時間浪費在自憐自艾中，是我要努力做到。<br>我有點沒有想到我會是一個受獎勵驅動力很高的人</p>
</blockquote>
<h2 id="人際交往風格"><a href="#人際交往風格" class="headerlink" title="人際交往風格"></a>人際交往風格</h2><ul>
<li>相對於比較組，你的反應表明你在很大程度上更傾向於尋求社交互動並會因其而感到充滿活力。</li>
<li>相對於比較組，你的反應表明你在非常大的程度上傾向於表現得更自信、決斷和有把握。</li>
<li>你的反應表明，在管理自己的行為以對社交線索作出回應方面，你的傾向程度與比較組中的其他大部分人相同。</li>
<li>相對於比較組，你的反應表明你在相當程度上傾向於採取與其他人的需求相符，而不是與自己的需求相符的行動。</li>
</ul>
<h2 id="思維風格"><a href="#思維風格" class="headerlink" title="思維風格"></a>思維風格</h2><ul>
<li><strong>相對於比較組，你的反應表明在做決策時，你略微地傾向於將注意力集中在直接成果</strong>。<br>（直白的說，我就我可能更注重短期利益，沒很好的長期收益的概念）</li>
<li>在對世界和未來擁有積極看法上，你的傾向程度與比較組中的其他大部分人相同。在預計行動最後會產生更為有利或不太有利的結果上，你的預期較為合理。</li>
<li>你的結果表明，在做涉及到一定程度⻛險的決策前，你在會仔細考慮⻛險收益比上的傾向程度與比較組中的其他大部分人相同。</li>
<li><strong>相對於比較組，你的反應表明你在做決策時傾向於需要程度稍微較大的確定性。當未來較為容易預測時，你也會感到較為自在</strong>。</li>
<li>解決問題時，你在嘗試新穎和實驗性的方法上的傾向程度與比較組中的其他大部分人相同。</li>
<li>你的反應表明，在理性決策⻛格方面，你的傾向程度與比較組中的其他大部分人相同。在做決策時，你的思維可能會顯得周密、客觀和具有批判性。</li>
<li>相對於比較組，在回應前仔細考慮自己的行動方面，你的傾向程度與比較組中的其他大部分人相同。</li>
<li>在偏愛多樣性、經常性的變化，以及喜好嘗試新事物上，你的可能性與比較組中的其他大部分人相同。</li>
<li>在創造性地思考和擁有自由暢通的思路及抽象性思路上，你的傾向程度與比較組中的其他大部分人相同。</li>
</ul>
<blockquote>
<p>有時比較短視的想法，可能會限制更好的長期發展。可以培養一些短期不會有太大效果，但對於長期的人生會有比較好收益的習慣。</p>
</blockquote>
]]></content>
      <categories>
        <category>Daily</category>
      </categories>
      <tags>
        <tag>test</tag>
        <tag>reflection</tag>
      </tags>
  </entry>
  <entry>
    <title>Books |《數據挖掘與數據化運營實戰》Reading notes (1)</title>
    <url>/Books%EF%BD%9C%E3%80%8A%E6%95%B8%E6%93%9A%E6%8C%96%E6%8E%98%E8%88%87%E6%95%B8%E6%93%9A%E5%8C%96%E9%81%8B%E7%87%9F%E5%AF%A6%E6%88%B0%E3%80%8B/</url>
    <content><![CDATA[<p>   一直對數據分析很感興趣，但在學校學習的都比較簡單，又礙於自己的懶惰，一直沒有深入了解。暑假藉著報名參加了一個數據分析的比賽（雖然在初賽就折戟了😂其實一點也不意外）讓自己比較有動力繼續更深入的學習一些數據處理的方法，當然還有如何用機器學習的方式去實現進一步的預測，以及決策。</p>
<p>   也是在圖書館閒逛的時候，意外發現的這本《數據挖掘與數據化運營實戰》，相較於其他的一些數據挖掘和機器學習的書籍，這本書更偏向於實戰應用。它沒有過多的數學推導，比較測重於數據分析整體流程的一個介紹，對於一個初學者來說是一部很好的入門書籍。使初學者更加清楚的知道數據分析的應用情境，數據挖掘有哪些流程步驟，在每個步驟中我們該如何選擇最好的方法來達到期望的效果等等。總之對於一個數據和編程小白來說這是一本非常友好的入門書籍，看後會對數據挖掘有一個比較宏觀的認識，當然想要了解算法原理之類的一些核心技能這本書就不太夠用了，這些就需要更深入的一些書籍去了解了。</p>
<p>我的閱讀順序可能比較奇怪，所以Reading notes也是各個章節穿插著紀錄的。</p>
<h1 id="第六章-數據挖掘項目完整應用案例演示"><a href="#第六章-數據挖掘項目完整應用案例演示" class="headerlink" title="第六章 數據挖掘項目完整應用案例演示"></a>第六章 數據挖掘項目完整應用案例演示</h1><h2 id="綜述"><a href="#綜述" class="headerlink" title="綜述"></a>綜述</h2><p>幾個希望傳遞的重點：</p>
<ul>
<li>數據挖掘是有一定的基本流程和順序的，按照流程進行挖掘是數據挖掘分析嚴謹性的體現。</li>
<li>數據挖掘只是數據運營的一部分，沒有落地應用的數據挖掘嚴格意義上還不能算是“完成”。</li>
<li>落地應用中的運營方案對模型的應用效果影響極大，所以數據分析師不僅僅要熟悉數據分析和模型的搭建，還要熟悉與運營相關的業務。</li>
</ul>
<h2 id="項目背景和業務分析需求的提出"><a href="#項目背景和業務分析需求的提出" class="headerlink" title="項目背景和業務分析需求的提出"></a>項目背景和業務分析需求的提出</h2><ul>
<li>背景：某互聯網公司“免費用戶運營團隊”，需要不斷將免費用戶提升為付費用戶，來從電子商務中獲取更大的利益。</li>
<li>困境：高活躍度的群體付費轉化率最高，但是高活躍度用戶的流失比較大，有相當比例的高活躍度用戶會快速的跌落到中低活躍度中。</li>
</ul>
<h2 id="數據分析師參與需求討論"><a href="#數據分析師參與需求討論" class="headerlink" title="數據分析師參與需求討論"></a>數據分析師參與需求討論</h2><p>分析師與運營方進行了需求的討論。<br>討論的目的主要是：</p>
<ul>
<li>針對需求收集相關的背景數據和指標，與業務方一起熟悉背景中的相關業務邏輯，並收集業務方對需求的相關建議和看法。這些信息對需求的確認和思路的規劃乃至後期的分析都至關重要。</li>
<li>從數據的分析的角度評估業務分析是否合理。某些情況下，某些分析就是“偽命題”</li>
</ul>
<h2 id="制訂需求分析框架和分析計畫"><a href="#制訂需求分析框架和分析計畫" class="headerlink" title="制訂需求分析框架和分析計畫"></a>制訂需求分析框架和分析計畫</h2><p>初步了解了背景，要制訂初步的分析計畫和分析框架。<br>分析框架的主要內容：</p>
<ul>
<li><strong>分析需求轉化成數據分析項目中目標變量的定義</strong>。具體到之前案例，定義“高度活躍免費用戶的流失”：[在某個時間點“A點”用戶是滿足高活躍用戶標準要求的（這時是屬於高活躍用戶群體的），隨後過“A點”7天（這個7天也是根據運營的時間節奏來訂出的），該高活躍用戶跌入至中低活躍用戶中，並在過“A點”14天，即兩週之後仍然沒有回到高活躍的標準。]這只是初步的定義，隨著後期進行數據抽取，並與業務方討論後，有跟深入的分析後，上述的定義可以被修改和完善，修改和完善的終極目的是為了數據分析和挖掘工作能最有效的達到預期效果，並提升業務工作效率。</li>
<li><strong>分析思路的大致描述</strong>。具體到上述方案，通過搭建分類模型來比較準確的鎖定有可能流失的用戶群體。</li>
<li><strong>分析樣本的數據抽取規則</strong>。數據抽取規則因項目而定，基本上是根據上面的目標變量的定義，選擇一個合適的時間窗口，然後抽取一定的樣本數據。</li>
<li><strong>潛在分析變量（模型輸入變量）的大致圈定和羅列</strong>。經過前期的分析和討論，分析師已經確定了大致圈定的相關變量（從業務經驗判斷和以往分析中得來），上述案例中整理出大約63個原始變量。羅列出這些似乎對目標變量的預測有意義的相關變量。</li>
<li><strong>分析過程中的項目風險思考和主要應對策略</strong>。具體到上述案例，項目風險思考主要包括模型效果不好的可能性，即有可能分類模型的思路被證明是不好的，也有可能是模型效果不好，或者準確度不高，或者模型不穩定。是否有相應的分析對策來部分彌補，若分類模型的思路被證明是行不通的，可退而求其次進行流失用戶的群體特徵細分，或者重新定義流失用戶等。</li>
<li><strong>項目落地應用價值分析和展望</strong>。針對上述方案，主要有3個方面：模型投入應用有提前鎖定目標群體，使運營方有針對性的開展挽留工作；可以將建模過程中發現的有價值的，最可能影響流失的重要字段和指標選出來提供給運營方，用於制訂運營方案和策略的參考和依據；準對影響流失的核心指標和字段，可以提供給相關業務方，開展針對性的策略。</li>
</ul>
<p>書中的項目所給出的一個參考時間表</p>
<blockquote>
<p>分析計畫時間表舉例：<br>11.5～11.11  數據的抽樣和摸底階段<br>11.12～11.18 數據的前期分析階段<br>11.19～11.30 建模時間和業務方討論時間<br>12.1～12.9   模型驗證階段，驗證通過，提交分析結果和運營方案建議<br>12.10～12.23 運營方案的落地應用實施<br>12.24～1.8   效果評估和總結，優化方案，落地應用並監控效果</p>
</blockquote>
<h2 id="抽取樣本數據，熟悉數據，數據清洗和摸底"><a href="#抽取樣本數據，熟悉數據，數據清洗和摸底" class="headerlink" title="抽取樣本數據，熟悉數據，數據清洗和摸底"></a>抽取樣本數據，熟悉數據，數據清洗和摸底</h2><ul>
<li>本階段的主要內容是：根據前期的分析和建模思路，以及初步圈定的分析字段（分析變量）編寫代碼，從數據庫中提取分析建模所需的樣本數據；通過對樣本數據的熟悉和摸底，找到無效數據，髒數據，錯誤數據等。並且對樣本數據中存在的這些明顯的數據質量問題進行清洗，剔除，轉換，同時視具體業務場景和項目需求，決定是否產生衍生變量，以及怎樣衍生等。</li>
<li>針對數據質量的對策：<br>通過對原始樣本數據和原始變量的摸底，排查，發現有些變量缺失值高達50%。經過研究發現這些缺失是數據倉庫儲存過程中的記錄缺失，或是由於產品優化後的業務邏輯更改所造成的。這些無法滾回的數據，可以選擇直接刪除。<ul>
<li>通過輸入變量之間的相關性分析，找出潛在共線性問題的相關輸入變量，對於高度線性相關的變量只保留一個。</li>
<li>在數據庫的數據回滾過程中造成了某些字節的嚴重不符合邏輯或明顯自相矛盾，比如用戶最近30天登陸網站次數為0。針對如此不符合邏輯的數據，直接重新回滾數據，直到數據正確為止。</li>
</ul>
</li>
</ul>
<p>經過處理，即刪除嚴重缺失數據，素居倉庫重新回滾自相矛盾的數據，對高度相關性的數據部分有取有捨，在本階段共保留了36個表有意義的字段（變量）合相關數據。（最開始是63個）<br>（第8章會比較詳細的講到數據清洗）</p>
<h2 id="按計畫初步搭建挖掘模型"><a href="#按計畫初步搭建挖掘模型" class="headerlink" title="按計畫初步搭建挖掘模型"></a>按計畫初步搭建挖掘模型</h2><p>對數據進行初步的摸底和清洗之後，就進入初步搭建挖掘模型階段了。在該階段，包括3個主要的工作內容:<br>進一步篩選模型的輸入變量。最終靜如模型的輸入變量應遵循“少而精”的總原則。該原則一方面能提高模型的穩定性，利益方面也是為了有效提升模型的預測精準度。關於如何刪選模型的輸入變量（8.6節，9.3.3節，第十章中會有比較詳細的分析。）<br>嘗試不同的挖掘算法和分析方法，並比較不同方案的效果，效率和穩定性。關於模型的比較和優化。7.4節有比較詳細的總結。（這裡使用了Neural network；Reg；Tree這三種，還需要有一條Baseline）<br>整理經過模型挑選出來的與目標變量的預測最相關的一系列核心輸入變量，將其作為與業務方討論落地應用時的參考和建議。</p>
<h2 id="與業務方討論模型的初步結論，提出新的思路和模型優化方案"><a href="#與業務方討論模型的初步結論，提出新的思路和模型優化方案" class="headerlink" title="與業務方討論模型的初步結論，提出新的思路和模型優化方案"></a>與業務方討論模型的初步結論，提出新的思路和模型優化方案</h2><p>在本階段，需要整理模型的初步報告，結論，以及對主要預測字段（特徵）進行提煉，還要通過與業務方溝通和分享，在此基礎上討論出模型的可能優化方向，並對落地應用的方案進行討論，同時羅列出注意事項。<br>具體針對這個項目而言，除了模型比較之外，還對核心自變量進行了整理提煉，並進行了權重排序。<br>“預測模型的搭建和完善也跟網站分析一樣，遵循著‘持續優化，永無止境’”的規律。</p>
<h2 id="按優化方案重新抽取樣本並建模，提煉結論並驗證模型"><a href="#按優化方案重新抽取樣本並建模，提煉結論並驗證模型" class="headerlink" title="按優化方案重新抽取樣本並建模，提煉結論並驗證模型"></a>按優化方案重新抽取樣本並建模，提煉結論並驗證模型</h2><p>在上述優化方案和新增衍生變量的基礎上，重新抽取樣本，一方面驗證之前的重要猜想；另一方面嘗試搭建新的模型提升預測效果。增加新的衍生變量後重複之前的測試，看哪一個模型效果好。這裡有提到“初步可以認為，目前的神經網絡模型相比於其他模型而言有更好的預測效果，可以更多的有效鎖定有流失風險的用戶”<br>模型建好後還需要用新的數據來驗證模型的穩定性。</p>
<h2 id="完成分析報告和落地應用的建議"><a href="#完成分析報告和落地應用的建議" class="headerlink" title="完成分析報告和落地應用的建議"></a>完成分析報告和落地應用的建議</h2><p>在上述模型優化和驗證的基礎上，提交給業務方一份詳細完整的項目結論和應用建議，包括的內容應該有：<br>模型的預測效果和效率，以及在最新的實際數據中驗證模型的結果，即模型穩定性。<br>通過模型整理出來的可以作為營運參考的重要自變量及相應特徵，規律。<br>數據分析師根據模型效果和效率數據提出的落地應用的分層建議，以及相應的運營建議，其包括：預測模型打分應用基礎上進一步的客戶特徵分層，相應細分群體運營通道的選擇等。</p>
<h2 id="制定具體的落地應用方案和評估方案"><a href="#制定具體的落地應用方案和評估方案" class="headerlink" title="制定具體的落地應用方案和評估方案"></a>制定具體的落地應用方案和評估方案</h2><h2 id="方案落地應用，並跟蹤評估"><a href="#方案落地應用，並跟蹤評估" class="headerlink" title="方案落地應用，並跟蹤評估"></a>方案落地應用，並跟蹤評估</h2><h2 id="落地應用方案在實際效果評估後，不斷修正完善"><a href="#落地應用方案在實際效果評估後，不斷修正完善" class="headerlink" title="落地應用方案在實際效果評估後，不斷修正完善"></a>落地應用方案在實際效果評估後，不斷修正完善</h2><h2 id="不同運營方案的評估，總結和反饋"><a href="#不同運營方案的評估，總結和反饋" class="headerlink" title="不同運營方案的評估，總結和反饋"></a>不同運營方案的評估，總結和反饋</h2><h2 id="醒目應用後的總結和反思"><a href="#醒目應用後的總結和反思" class="headerlink" title="醒目應用後的總結和反思"></a>醒目應用後的總結和反思</h2><p>“完美的分析結論和模型搭建只是數據化運營萬里長城的第一步”，想要模型正真推動業務的效率和效益，模型落地應用的環節更加關鍵，更加重要，更加複雜。</p>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>reading notes</tag>
        <tag>data science</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown 入門</title>
    <url>/Markdown%E5%85%A5%E9%96%80/</url>
    <content><![CDATA[<h1 id="Hexo中Markdown的一些基本語法"><a href="#Hexo中Markdown的一些基本語法" class="headerlink" title="Hexo中Markdown的一些基本語法"></a>Hexo中Markdown的一些基本語法</h1><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><pre><code>分段：兩個回車
換行：回車
標題：# ~ ######，#號的個數表示幾級標題，即表示一級標題到六級標題
強調：**文字** ， __文字__ ， _文字_ ， *文字* ， 文字
引用：&gt; 注意後面緊跟個空格
表格：- 和 | 分割行和列 ， : 控制對其方式</code></pre><h3 id="標題"><a href="#標題" class="headerlink" title="標題"></a>標題</h3><pre><code># 一級標題
## 二級標題
### 三級標題
###### 六級標題</code></pre><p>效果如下：</p>
<h1 id="一級標題"><a href="#一級標題" class="headerlink" title="一級標題"></a>一級標題</h1><h2 id="二級標題"><a href="#二級標題" class="headerlink" title="二級標題"></a>二級標題</h2><h3 id="三級標題"><a href="#三級標題" class="headerlink" title="三級標題"></a>三級標題</h3><h6 id="六級標題"><a href="#六級標題" class="headerlink" title="六級標題"></a>六級標題</h6><h3 id="強調"><a href="#強調" class="headerlink" title="強調"></a>強調</h3><pre><code>**加粗**
*傾斜*
***傾斜加粗***
~~加刪除線~~
`高亮突出背景色`</code></pre><p>效果如下：<br><strong>加粗</strong><br><em>傾斜</em><br><strong><em>傾斜加粗</em></strong><br><del>加刪除線</del><br><code>高亮突出背景色</code></p>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><pre><code>&gt; 這是引用內容
&gt;&gt; 這是引用內容
&gt;&gt;&gt;&gt;&gt;&gt; 這是引用內容</code></pre><p>效果如下：</p>
<blockquote>
<p>這是引用內容</p>
<blockquote>
<p>這是引用內容</p>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>這是引用內容</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<h3 id="分割線"><a href="#分割線" class="headerlink" title="分割線"></a>分割線</h3><p>三個或以上的 -，* 都可以</p>
<pre><code>***
******</code></pre><p>效果如下:</p>
<hr>
<hr>
]]></content>
      <categories>
        <category>Technological</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
