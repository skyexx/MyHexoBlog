<!DOCTYPE html>
<html lang>
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Skye">





<title>分類演算法實作 Titanic disaster dataset | Skye&#39;s Blog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


</head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Skye&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/categories">Categories</a>
                
                    <a class="menu-item" href="/tags">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/projects">Projects</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Skye&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/categories">Categories</a>
                
                    <a class="menu-item" href="/tags">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/projects">Projects</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">分類演算法實作 Titanic disaster dataset</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Skye</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">June 30, 2021&nbsp;&nbsp;15:07:11</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="資料處理流程"><a href="#資料處理流程" class="headerlink" title="資料處理流程"></a>資料處理流程</h2><ol>
<li>資料前處理<ul>
<li>簡單的Feature Engineering<ul>
<li>只保留Cabin的艙位號（前面的字母）。</li>
<li>把Name中的有一定含義的 title 元素提取出來，並將比較少用的title合併到比較常用的tittle中，建立一個新的類別“Title”</li>
<li>把姓氏提取出來，創建新的類別“Surname”</li>
</ul>
</li>
<li>Missing Data<ul>
<li>NA值 &amp; 空白值</li>
</ul>
</li>
<li>減少資料量<ul>
<li>屬性的篩選：刪掉不要的屬性</li>
</ul>
</li>
<li>正規化處理</li>
</ul>
</li>
<li>模型的建立<ul>
<li>隨機森林（Random Forest）</li>
<li>SVM（Support Vector Machines）</li>
<li>GBM（Gradient Boosting Machine）</li>
</ul>
</li>
<li>模型的解釋</li>
<li>預測及分析<ul>
<li>混淆矩陣</li>
<li>ROC</li>
<li>AUC</li>
</ul>
</li>
</ol>
<h2 id="資料前處理"><a href="#資料前處理" class="headerlink" title="資料前處理"></a>資料前處理</h2><h3 id="簡單的Feature-Engineering："><a href="#簡單的Feature-Engineering：" class="headerlink" title="簡單的Feature Engineering："></a>簡單的Feature Engineering：</h3><ul>
<li>只保留Cabin的艙位號（前面的字母）。</li>
<li>把Name中的有一定含義的 title 元素提取出來，並將比較少用的title合併到比較常用的tittle中，建立一個新的類別“Title”</li>
<li>把姓氏提取出來，創建新的類別“Surname”<br><img src="https://img-blog.csdnimg.cn/20210630161713992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><h3 id="Missing-data："><a href="#Missing-data：" class="headerlink" title="Missing data："></a>Missing data：</h3></li>
</ul>
<p>NA值主要來自Age和Cabin（Survived的缺失值，是test中填補的NA）</p>
<p><img src="https://img-blog.csdnimg.cn/20210630162043986.png#pic_center" alt="在这里插入图片描述"></p>
<pre><code>方法：這邊我們選擇用mice填補Age和Fare的缺失值

查看填補之後的結果：</code></pre><p><img src="https://img-blog.csdnimg.cn/20210630162117560.png" alt="在这里插入图片描述"></p>
<p>空值：只來自Embarked</p>
<p>  <img src="https://img-blog.csdnimg.cn/20210630162218181.png" alt="在这里插入图片描述"></p>
<pre><code>查看Embarked的類別及各個類別的資料筆數，選擇資料筆數最的類別（“S”）填補填補到Embarked的空值中</code></pre><p><img src="https://img-blog.csdnimg.cn/20210630162440826.png" alt="在这里插入图片描述"></p>
<h3 id="減少資料量："><a href="#減少資料量：" class="headerlink" title="減少資料量："></a>減少資料量：</h3><p>屬性的篩選：刪掉不要的屬性</p>
<ul>
<li>Name &amp; Surname：類別太多了，並且沒有什麼特別的用途。</li>
<li>Ticket：裡面都是一些隨機的數字，沒有特多含義，並且是多值屬性不好處理。</li>
<li>Cabin：有太多的NA值，並且為類別變數不好填充，如果給一個Ncabin的類別，會使得屬性非常unbalance。</li>
<li>PassengerId：只是一個序列號，沒有太多的含義。<img src="https://img-blog.csdnimg.cn/2021063016251447.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><h3 id="Data-正規化："><a href="#Data-正規化：" class="headerlink" title="Data 正規化："></a>Data 正規化：</h3></li>
</ul>
<p>數值變量的range沒有特別的大，所以沒有做特別的正規化處理</p>
<h2 id="模型的建立"><a href="#模型的建立" class="headerlink" title="模型的建立"></a>模型的建立</h2><p>因為test 資料集中沒有“Survuved”欄位，所以我們從train資料集中分出30%作為驗證集。</p>
<p>剩下的train中的70%資料用於訓練模型，訓練中也會做cross-validation。</p>
<p>下面建立了三個模型：</p>
<ul>
<li>隨機森林（Random Forest）</li>
<li>SVM（Support Vector Machines）</li>
<li>GBM（Gradient Boosting Machine）</li>
<li>⚠️ KNN一般可以作為分類的baseline</li>
</ul>
<h3 id="隨機森林："><a href="#隨機森林：" class="headerlink" title="隨機森林："></a>隨機森林：</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 隨機森林</span></span><br><span class="line">set.seed(<span class="number">100</span>)</span><br><span class="line">titanic_rf &lt;- train(factor(Survived) ~ ., data=train_data, method=<span class="string">'rf'</span>, </span><br><span class="line">										trControl=trainControl(method=<span class="string">"cv"</span>, number=<span class="number">5</span>))</span><br><span class="line">titanic_rf</span><br><span class="line">plot(titanic_rf)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20210630162556173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我們可以看出選擇出的最好的模型是mtry = 3的時候。</p>
<h3 id="SVM："><a href="#SVM：" class="headerlink" title="SVM："></a>SVM：</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SVM</span></span><br><span class="line">set.seed(<span class="number">100</span>)</span><br><span class="line">titanic_svm &lt;- train(factor(Survived) ~., data=SVMtrain_data, method=<span class="string">'svmRadial'</span>, preProcess= c(<span class="string">'center'</span>, <span class="string">'scale'</span>), </span><br><span class="line">                     trControl= trainControl(method=<span class="string">"cv"</span>, number=<span class="number">5</span>, classProbs = <span class="literal">T</span>))</span><br><span class="line">titanic_svm</span><br><span class="line">plot(titanic_svm</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20210630162643796.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我們可以看出最好的模型是 sigma=0.2828，C=0.25的時候。</p>
<h3 id="GBM："><a href="#GBM：" class="headerlink" title="GBM："></a>GBM：</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (GBM) model</span></span><br><span class="line">set.seed(<span class="number">100</span>)</span><br><span class="line">titanic_gbm &lt;- train(factor(Survived) ~., data=train_data, method=<span class="string">'gbm'</span>, preProcess= c(<span class="string">'center'</span>, <span class="string">'scale'</span>), </span><br><span class="line">                     trControl=trainControl(method=<span class="string">"cv"</span>, number=<span class="number">7</span>), verbose=<span class="literal">FALSE</span>)</span><br><span class="line">print(titanic_gbm)</span><br><span class="line">plot(titanic_gbm)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20210630162715791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我們可以看出GBM選出的最好的模型是n.trees=200，且深度為3 interaction.depth = 3的模型。</p>
<h2 id="模型的解釋"><a href="#模型的解釋" class="headerlink" title="模型的解釋"></a>模型的解釋</h2><p>這裡直接利用<code>library(&quot;DALEX&quot;)</code>包的解釋函數對三個模型進行解釋性分析</p>
<h3 id="累積殘差分佈："><a href="#累積殘差分佈：" class="headerlink" title="累積殘差分佈："></a>累積殘差分佈：</h3><p><img src="https://img-blog.csdnimg.cn/20210630162745616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>由上圖我們可以看，綠色的線在最上方，也就是SVM中大部分的樣本殘差都比較大。而紅色的線是RF模型，它的大部分的樣本殘差都比較小。可以看出樹的模型的殘差線對於SVM這類的模型都要來的比較小一些。</p>
<h3 id="變數重要性分析："><a href="#變數重要性分析：" class="headerlink" title="變數重要性分析："></a>變數重要性分析：</h3><p><img src="https://img-blog.csdnimg.cn/20210630162825232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>可以看出三個模型中的變數重要性的排序基本上是一樣的。</p>
<h2 id="測試訓練好的模型並分析結果"><a href="#測試訓練好的模型並分析結果" class="headerlink" title="測試訓練好的模型並分析結果"></a>測試訓練好的模型並分析結果</h2><p>我們用之前從train的資料集中分出的valid資料來做各個模型的測試</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用不同的已經訓練好的模型分類預測：</span></span><br><span class="line">rf_probs = predict(titanic_rf,valid_feature,type = <span class="string">"prob"</span>) <span class="comment"># 訓練集中的預測情形</span></span><br><span class="line">svm_probs = predict(titanic_svm,valid_feature,type = <span class="string">"prob"</span>)</span><br><span class="line">gbm_probs = predict(titanic_gbm,valid_feature,type = <span class="string">"prob"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="預測出來的結果（這邊僅以Random-Forrest的處理過程為例）："><a href="#預測出來的結果（這邊僅以Random-Forrest的處理過程為例）：" class="headerlink" title="預測出來的結果（這邊僅以Random Forrest的處理過程為例）："></a>預測出來的結果（這邊僅以Random Forrest的處理過程為例）：</h3><p>如圖：<br><img src="https://img-blog.csdnimg.cn/20210630162927787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看訓練集的預測情形</span></span><br><span class="line">rf_summaryvalid &lt;- rf_validDataPred %&gt;% </span><br><span class="line">  filter(yes &gt; <span class="number">0.5</span>) %&gt;%                           <span class="comment"># yes 為預測存活下來的機率</span></span><br><span class="line">  summarise(count = n(), </span><br><span class="line">            accuracy_rate = mean(Survived))              <span class="comment">#  統計預測存活下來的人數與實際比較的準確率</span></span><br><span class="line"></span><br><span class="line">rf_summaryvalid</span><br><span class="line"><span class="comment"># count  accuracy_rate</span></span><br><span class="line"><span class="comment"># 106	 0.6981132</span></span><br></pre></td></tr></table></figure>

<p>我們將是否存活的機率的門檻設置為0.5，我們可以看到計算出來的準確率為：0.6981132</p>
<p>我們想了解不同門檻值的預測情況，所以就先粗略切了[0,0.5,0.55,0.6,0.65,0.7,0.8,1]這些區間來看看，是否有更好的門檻值設定。</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看測試集分類機率在不同門檻值下的預測情況</span></span><br><span class="line">rf_summaryvalidCut &lt;- rf_validDataPred %&gt;% </span><br><span class="line">  <span class="comment"># 看不同的分類機率做區間查看其準確率</span></span><br><span class="line">  mutate(interval = cut(yes,breaks = c(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">0.55</span>,<span class="number">0.6</span>,<span class="number">0.65</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">1</span>),include.lowest = <span class="literal">T</span>)) %&gt;%  </span><br><span class="line">  group_by(interval) %&gt;%</span><br><span class="line">  summarise(count = n(), </span><br><span class="line">            accuracy_rate = mean(Survived))</span><br><span class="line"></span><br><span class="line">rf_summaryvalidCut</span><br></pre></td></tr></table></figure>

<p>根據下表的分佈情況似乎切在0.8左右會更好<br><img src="https://img-blog.csdnimg.cn/20210630163015754.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="混淆矩陣-："><a href="#混淆矩陣-：" class="headerlink" title="混淆矩陣 ："></a><strong>混淆矩陣 ：</strong></h3><p>那麼我將預測結果依照分類機率大於0.8當成1來建立混淆矩陣，並對三個模型都建立了混淆矩陣來進行對比：<img src="https://img-blog.csdnimg.cn/20210630163057830.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>可以看出三個模型：</p>
<ul>
<li><p>預測的準確率（Accuracy）以及F1 Score 最高的都是 Random Forrest</p>
</li>
<li><p>三個模型主要犯的都是FN（false negative）的錯誤，既將實際存活的人判斷為了死亡。</p>
</li>
<li><p>同時我們可以看到SVM在準確率（Accuracy）上和其他兩個模型相差的並不多，但是 F1 Score 的分數就要比其他兩個模型低很多。</p>
<ul>
<li><p>Accuracy = (TP+TN)/(TP+FP+FN+TN)</p>
</li>
<li><p>Recall = TP/(TP+FN)</p>
</li>
<li><p>Precision = TP/(TP+FP)</p>
</li>
<li><p>F1-score = 2 * Precision * Recall / (Precision + Recall)</p>
<p>那麼我們可以根據F1-score 的公式看出他是Precision和Recall两者調和平均，而Precision和Recall两者可以比較好的度量分類錯誤的情況。所以我們可以推測出SVM的模型對於FP和FN的判斷不是很好，但對於TP和TN的預測效果還是可以的。</p>
</li>
</ul>
</li>
</ul>
<h3 id="ROC："><a href="#ROC：" class="headerlink" title="ROC："></a>ROC：</h3><p>上面的混淆矩陣我是透過比較粗糙的方式切出的 0.8 作為門檻來進行三個模型的比較的。</p>
<p>但是想進一步比較三個模型效果還是應該來看一個更為細緻的ROC曲線和AUC的值。</p>
<p>紅線為：Random Forest</p>
<ul>
<li>最佳的切分值：0.835 or 0.737</li>
</ul>
<p>綠線為：SVM</p>
<ul>
<li>最佳的切分值：0.808 or 0.798</li>
</ul>
<p>藍線為：GBM</p>
<ul>
<li>最佳的切分值：0.885 or 0.717</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20210630163241918.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NreWV4eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在ROC的圖中越是靠近左上角的部分他的TPR越大而FPR越小，也就是模型的效果就越好。可以看出藍線和紅線都完全包裹在綠線的外面，所以我們可以認為Random Forest和GBM做為這個資料集的分類器效果都比SVM更好。而Random Forest和GBM的比較我們我們只從ROC不能看出哪一個模型比較好，所以我們需要進一步分析兩個模型的AUC值。</p>
<h3 id="AUC："><a href="#AUC：" class="headerlink" title="AUC："></a>AUC：</h3><p>AUC也就是ROC曲線下方的面積，AUC值越大的分類器，正確率越高。</p>
<p>根據 AUC 比較模型的效果也就是：Random Forest(0.844) &gt; GBM(0.836) &gt; SVM(0.795)</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Skye</span>
                    </p>
                
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
            
            <a class="next" rel="next" href="/文字探勘-3｜用R做情緒分析/">文字探勘-3｜用R做情緒分析</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Skye | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
